{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "Install required dependencies, set up GPU, import libraries, and clone project repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install scipy pyyaml fire seaborn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError(\"GPU is not available. Please ensure you are using a Colab runtime with GPU enabled.\")\n",
    "else:\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# importing required libraries\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "\n",
    "import math\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "Mount Google Drive to persist data and results between Colab sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive to persist data and results\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set the working directory to a folder in Google Drive\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/ColabNotebooks/hessian-ood', exist_ok=True)\n",
    "%cd /content/drive/MyDrive/ColabNotebooks/hessian-ood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "Define the Transformer model architecture including embedding layers, attention mechanisms, and feed-forward networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "##################### model definition ####################\n",
    "#####################################################\n",
    "\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, init=None, trainable=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: size of vocabulary\n",
    "        \"\"\"\n",
    "        super(Embedding, self).__init__()\n",
    "        if init is not None:\n",
    "            self.embed = nn.Embedding.from_pretrained(init).requires_grad_(trainable)\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, d_model).requires_grad_(trainable)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input vector\n",
    "        Returns:\n",
    "            out: embedding vector\n",
    "        \"\"\"\n",
    "        out = self.embed(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_seq_len, d_model, init=None, trainable=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_seq_len: maximium length of input sequence\n",
    "        Final embedding dimension is max_seq_len + static embedding dimension\n",
    "        \"\"\"\n",
    "\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        if init is not None:\n",
    "            self.pe = nn.Embedding.from_pretrained(init).requires_grad_(trainable)\n",
    "        else:\n",
    "            self.pe = nn.Embedding(max_seq_len, d_model).requires_grad_(trainable)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input vector\n",
    "        Returns:\n",
    "            out: output\n",
    "        \"\"\"\n",
    "        # append positional encodings to static embeddings\n",
    "        seq_len = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "        pos = torch.arange(0, seq_len, dtype=torch.long)\n",
    "        out = x + self.pe(pos).repeat(batch_size, 1, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "## following three definitions are for rotary embeddings\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    \"\"\"Rotary embedding helper function\"\"\"\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1]), (freqs_cis.shape, x.shape)\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "# The following implementation of multi-head attention is from\n",
    "# https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config, linear_attn=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = config.d_model\n",
    "        self.num_heads = config.num_heads\n",
    "        self.linear_attn = linear_attn\n",
    "        self.pos = config.pos\n",
    "        self.d_k = config.d_model // config.num_heads\n",
    "        assert (\n",
    "            config.d_model % config.num_heads == 0\n",
    "        ), \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.W_q = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_k = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_v = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_o = nn.Linear(config.d_model, config.d_model)\n",
    "\n",
    "        if config.pos == \"relative\":\n",
    "            self.att_bias = nn.Parameter(\n",
    "                torch.zeros(config.num_heads, config.max_seq_len, config.max_seq_len)\n",
    "            ).to(config.device)\n",
    "\n",
    "        if config.pos == \"rotary\":\n",
    "            self.freqs_cis = precompute_freqs_cis(\n",
    "                self.d_model // self.num_heads,\n",
    "                config.max_seq_len * 2,\n",
    "                config.rotary_theta,\n",
    "            ).to(config.device)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        assert mask is not None, \"Mask=None is not supported now\"\n",
    "\n",
    "        if self.pos == \"rotary\":\n",
    "            T = Q.size(2)\n",
    "            # expected shape for apply_rotary_emb: (batch_size, max_seq_len, num_head, d_head)\n",
    "            Q, K = apply_rotary_emb(\n",
    "                Q.transpose(1, 2), K.transpose(1, 2), freqs_cis=self.freqs_cis[:T]\n",
    "            )\n",
    "            Q, K = Q.transpose(1, 2), K.transpose(1, 2)\n",
    "\n",
    "        QK_vals = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if self.pos == \"relative\":\n",
    "            T = QK_vals.size(2)\n",
    "            QK_vals = QK_vals + self.att_bias[:, :T, :T].view(1, self.num_heads, T, T)\n",
    "\n",
    "        if mask is not None:\n",
    "            if not self.linear_attn:\n",
    "                attn_scores = QK_vals.masked_fill(mask == 0, -1e9)\n",
    "                attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "            else:\n",
    "                attn_scores = QK_vals.masked_fill(mask == 0, 0)\n",
    "                attn_probs = attn_scores\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output, (attn_probs, QK_vals)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None, output_attn=False):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attn_output, attn_probs = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        output = (output, attn_probs) if output_attn else output\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward2(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=None, norm=False):\n",
    "        super(PositionWiseFeedForward2, self).__init__()\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = dropout\n",
    "        self.norm = norm\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln(x) if self.norm else x\n",
    "        x = self.fc2(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(x) if self.drop is not None else x\n",
    "        return x\n",
    "\n",
    "\n",
    "## main Transformer definitions\n",
    "class TFBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.residual = config.residual\n",
    "        self.drop = config.dropout\n",
    "        self.norm = config.norm\n",
    "        self.ff_dim = config.ff_dim\n",
    "        self.linear_attn = config.linear_attn\n",
    "        self.mlp = config.mlp\n",
    "\n",
    "        # initiating layers\n",
    "        self.mha = MultiHeadAttention(config, linear_attn=config.linear_attn)\n",
    "        self.ln_1 = nn.LayerNorm(config.d_model, elementwise_affine=config.trainable_norm)\n",
    "        self.ln_2 = nn.LayerNorm(config.d_model, elementwise_affine=config.trainable_norm)\n",
    "        self.dropout1 = nn.Dropout(config.dropout)\n",
    "        self.dropout2 = nn.Dropout(config.dropout)\n",
    "        if config.mlp:\n",
    "            self.feed_forward = PositionWiseFeedForward(config.d_model, config.ff_dim)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.ln_1(x) if self.norm else x\n",
    "        attn_output = self.mha(out, out, out, mask)\n",
    "        out = self.dropout1(attn_output) if self.drop is not None else attn_output\n",
    "        x = x + out if self.residual else x\n",
    "        if self.mlp:\n",
    "            out = self.ln_2(x) if self.norm else x\n",
    "            out = self.feed_forward(out)\n",
    "            out = self.dropout2(out)\n",
    "            x = x + out if self.residual else x\n",
    "        return x\n",
    "\n",
    "\n",
    "class TFModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.pos = config.pos\n",
    "        self.num_layers = config.num_layers\n",
    "        self.output_norm = config.output_norm\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.embed = Embedding(config.vocab_size, config.d_model)\n",
    "        if self.pos is None:\n",
    "            self.pos_embed = PositionalEmbedding(config.max_seq_len, config.d_model)\n",
    "\n",
    "        self.h = nn.ModuleList([TFBlock(config) for i in range(config.num_layers)])\n",
    "        self.ln_f = nn.LayerNorm(config.d_model, elementwise_affine=config.trainable_norm)\n",
    "        self.fc = nn.Linear(config.d_model, config.vocab_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        x = (\n",
    "            self.embed(src)\n",
    "            if self.pos in [\"relative\", \"rotary\"]\n",
    "            else self.pos_embed(self.embed(src))\n",
    "        )\n",
    "        seq_len = x.size(1)\n",
    "        mask = (\n",
    "            torch.tril(torch.ones(seq_len, seq_len))\n",
    "            .unsqueeze(0)\n",
    "            .unsqueeze(0)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        out = x\n",
    "        for i, (block) in enumerate(self.h):\n",
    "            out = block(out, mask)\n",
    "        out = self.ln_f(out) if self.output_norm else out\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Data Generation\n",
    "setup data generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "##################### Data generation ####################\n",
    "#####################################################\n",
    "\n",
    "\n",
    "def gen_simple_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    pattern=\"random\",\n",
    "    pattern_sample_len=None,\n",
    "    rep_l=11,\n",
    "    rep_h=20,\n",
    "    return_lens=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on different patterns.\n",
    "    Simple repetitions of certain short-ranged patterns.\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        pattern: a string that indicated the short pattern used for generating sequence data, or a 1-d numpy array\n",
    "        pattern_sample_len: the length of sampled patterns, only used when pattern ='random'\n",
    "        return_lens: if True, returns repetition length for each seq\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long; if return_len, returns (data, lens)\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    lens = np.zeros(sample_size, dtype=int)\n",
    "    id0, id1, id2 = 0, 1, 2\n",
    "    if max_seq_len % 12 != 0:\n",
    "        warnings.warn(\"max_seq_len is not divisible by 12, which may cause issues!\")\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        if pattern == \"random\":\n",
    "            if pattern_sample_len is None:\n",
    "                pattern_len = np.random.randint(low=rep_l, high=rep_h)\n",
    "            pattern_sample = torch.multinomial(\n",
    "                torch.ones(vocab_size) / vocab_size, pattern_len, replacement=True\n",
    "            )\n",
    "            num_repeat = max_seq_len // pattern_len + 1\n",
    "            r = pattern_len * num_repeat - max_seq_len\n",
    "            tmp = vocab[pattern_sample].repeat(num_repeat)\n",
    "            start_pos = np.random.randint(low=0, high=r)\n",
    "            data[i, :] = tmp[start_pos : (start_pos + max_seq_len)]\n",
    "            lens[i] = pattern_len\n",
    "        else:  # for a given pattern\n",
    "            pattern_len = len(pattern)\n",
    "            num_repeat = max_seq_len // pattern_len + 1\n",
    "            r = pattern_len * num_repeat - max_seq_len\n",
    "            tmp = vocab[pattern].repeat(num_repeat)\n",
    "            start_pos = np.random.randint(low=0, high=r)\n",
    "            data[i, :] = tmp[start_pos : (start_pos + max_seq_len)]\n",
    "            # warnings.warn('Pattern argument may not receive a correct input!')\n",
    "            lens[i] = pattern_len\n",
    "\n",
    "    data = (data, lens) if return_lens else data\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_repetition_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    distr=None,\n",
    "    pattern_pool_size=None,\n",
    "    patterns=None,\n",
    "    rep_l=11,\n",
    "    rep_h=20,\n",
    "    num_repeat=2,\n",
    "    return_lens=False,\n",
    "):\n",
    "\n",
    "    vocab_size = vocab.size(0)\n",
    "    p = torch.ones(vocab_size) / vocab_size if distr is None else distr\n",
    "\n",
    "    data = torch.multinomial(p, sample_size * max_seq_len, replacement=True).view(\n",
    "        sample_size, max_seq_len\n",
    "    )\n",
    "    lens = np.zeros(sample_size, dtype=int)\n",
    "    starts = np.zeros((sample_size, num_repeat), dtype=int)\n",
    "\n",
    "    if pattern_pool_size is not None and patterns is None:\n",
    "        # given the size of pattern pool, sample patterns from distribution p with length uniformly drawn from rep_l and repl_h\n",
    "        patterns = []\n",
    "        pattern_len_all = np.random.randint(\n",
    "            low=rep_l, high=rep_h, size=pattern_pool_size\n",
    "        )\n",
    "        for t in range(pattern_pool_size):\n",
    "            pattern = torch.multinomial(p, pattern_len_all[t], replacement=True)\n",
    "            patterns.append(pattern)\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        if pattern_pool_size is None and patterns is None:\n",
    "            pattern_len = np.random.randint(low=rep_l, high=rep_h)\n",
    "            pattern_sample = torch.multinomial(p, pattern_len, replacement=True)\n",
    "        else:\n",
    "            pattern_sample = patterns[np.random.randint(low=0, high=pattern_pool_size)]\n",
    "            pattern_len = len(pattern_sample)\n",
    "\n",
    "        r = max_seq_len - pattern_len * num_repeat\n",
    "        gaps = torch.multinomial(torch.ones(r) / r, num_repeat, replacement=False)\n",
    "        gaps = torch.sort(gaps)[0]\n",
    "        gaps = torch.cat(\n",
    "            (\n",
    "                gaps[:1],\n",
    "                torch.tensor([gaps[i] - gaps[i - 1] for i in range(1, num_repeat)]),\n",
    "            )\n",
    "        )\n",
    "        start_pos = 0\n",
    "        for j in range(num_repeat):\n",
    "            start_pos = start_pos + gaps[j]\n",
    "            data[i, start_pos : (start_pos + pattern_len)] = pattern_sample\n",
    "            starts[i, j] = start_pos\n",
    "            start_pos = start_pos + pattern_len\n",
    "        lens[i] = pattern_len\n",
    "\n",
    "    data = (data, lens, starts, patterns) if return_lens else data\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_mod_add_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    distr=None,\n",
    "    pattern_pool_size=None,\n",
    "    patterns=None,\n",
    "    rep_l=11,\n",
    "    rep_h=20,\n",
    "    num_repeat=2,\n",
    "    return_lens=False,\n",
    "):\n",
    "\n",
    "    vocab_size = vocab.size(0)\n",
    "    p = torch.ones(vocab_size) / vocab_size if distr is None else distr\n",
    "\n",
    "    data = torch.multinomial(p, sample_size * max_seq_len, replacement=True).view(\n",
    "        sample_size, max_seq_len\n",
    "    )\n",
    "    lens = np.zeros(sample_size, dtype=int)\n",
    "    starts = np.zeros((sample_size, num_repeat), dtype=int)\n",
    "\n",
    "    if pattern_pool_size is not None and patterns is None:\n",
    "        # given the size of pattern pool, sample patterns from distribution p with length uniformly drawn from rep_l and repl_h\n",
    "        patterns = []\n",
    "        pattern_len_all = np.random.randint(\n",
    "            low=rep_l, high=rep_h, size=pattern_pool_size\n",
    "        )\n",
    "        for t in range(pattern_pool_size):\n",
    "            pattern = torch.multinomial(p, pattern_len_all[t], replacement=True)\n",
    "            patterns.append(pattern)\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        if pattern_pool_size is None and patterns is None:\n",
    "            pattern_len = np.random.randint(low=rep_l, high=rep_h)\n",
    "            pattern_sample = torch.multinomial(p, pattern_len, replacement=True)\n",
    "        else:\n",
    "            pattern_sample = patterns[np.random.randint(low=0, high=pattern_pool_size)]\n",
    "            pattern_len = len(pattern_sample)\n",
    "\n",
    "        r = max_seq_len - pattern_len * num_repeat\n",
    "        gaps = torch.multinomial(torch.ones(r) / r, num_repeat, replacement=False)\n",
    "        gaps = torch.sort(gaps)[0]\n",
    "        gaps = torch.cat(\n",
    "            (\n",
    "                gaps[:1],\n",
    "                torch.tensor([gaps[i] - gaps[i - 1] for i in range(1, num_repeat)]),\n",
    "            )\n",
    "        )\n",
    "        start_pos = 0\n",
    "        for j in range(num_repeat):\n",
    "            # start_pos = start_pos + gaps[j] comment this line for deterministic pattern location\n",
    "            data[i, start_pos : (start_pos + pattern_len)] = pattern_sample # if j == 0 else torch.cumsum(pattern_sample, dim=0) % vocab_size\n",
    "            starts[i, j] = start_pos\n",
    "            start_pos = start_pos + pattern_len\n",
    "        lens[i] = pattern_len\n",
    "\n",
    "    data = (data, lens, starts, patterns) if return_lens else data\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_simple_Aa_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    pattern=None,\n",
    "    pattern_sample_len=None,\n",
    "    rep_l=11,\n",
    "    rep_h=20,\n",
    "    return_lens=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate simple repetitions of certain short-ranged patterns. Each character has two versions (i.e., capitalization or not), sampled randomly\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        pattern: a string that indicated the short pattern used for generating sequence data, or a 1-d numpy array; if None, a random pattern will be sampled\n",
    "        pattern_sample_len: the length of sampled patterns, only used when pattern ='random'\n",
    "        return_lens: if True, returns repetition length for each seq\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long; if return_len, returns (data, lens)\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    vocab_halfsize = vocab_size // 2\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    lens = np.zeros(sample_size, dtype=int)\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        if pattern is None:\n",
    "            if pattern_sample_len is None:\n",
    "                pattern_len = np.random.randint(low=rep_l, high=rep_h)\n",
    "            pattern_sample = torch.multinomial(\n",
    "                torch.ones(vocab_halfsize) / vocab_halfsize,\n",
    "                pattern_len,\n",
    "                replacement=True,\n",
    "            )\n",
    "            num_repeat = (max_seq_len - 1) // pattern_len + 1\n",
    "            r = pattern_len * num_repeat - max_seq_len\n",
    "            tmp = torch.zeros(num_repeat * pattern_len)\n",
    "            for j in range(num_repeat):\n",
    "                is_upper_case = torch.bernoulli(torch.tensor([0.5])).long()\n",
    "                tmp[(j * pattern_len) : ((j + 1) * pattern_len)] = vocab[\n",
    "                    pattern_sample + is_upper_case * vocab_halfsize\n",
    "                ]\n",
    "            start_pos = np.random.randint(low=0, high=r + 1)\n",
    "            data[i, :] = tmp[start_pos : (start_pos + max_seq_len)]\n",
    "            lens[i] = pattern_len\n",
    "        else:  # for a given pattern\n",
    "            pattern_len = len(pattern)\n",
    "            num_repeat = (max_seq_len - 1) // pattern_len + 1\n",
    "            r = pattern_len * num_repeat - max_seq_len\n",
    "            tmp = torch.zeros(num_repeat * pattern_len)\n",
    "            for j in range(num_repeat):\n",
    "                is_upper_case = torch.bernoulli(torch.tensor([0.5])).long()\n",
    "                tmp[(j * pattern_len) : ((j + 1) * pattern_len)] = vocab[\n",
    "                    pattern + is_upper_case * vocab_halfsize\n",
    "                ]\n",
    "            start_pos = np.random.randint(low=0, high=r + 1)\n",
    "            data[i, :] = tmp[start_pos : (start_pos + max_seq_len)]\n",
    "            lens[i] = pattern_len\n",
    "\n",
    "    data = (data, lens) if return_lens else data\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_hmm_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    state_sizes,\n",
    "    transition_mat=None,\n",
    "    sig=1.5,\n",
    "    ioi=False,\n",
    "    special_tokens=None,\n",
    "    return_states=True,\n",
    "    return_tokens_rep=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate simple HMM data: (z_1,z_2,...,z_T) is a latent Markov chain with z_t in {1,2,...,K}\n",
    "    For each latent state z_t, observation is uniformly sampled from a set O_{z_t}\n",
    "    The set O_1, O_2, ... O_K are non-overlapping and their cardinality is given by state_sizes\n",
    "    sum_k state_sizes[k] must be no larger than vocab size.\n",
    "    When ioi is True, we either sample two tokens [A] [B] from O_1 (if special_tokens is None) or choose special_tokens,\n",
    "    and then set observables from O_1 to just repetition [A] [B] [A] [B] ...\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        state_sizes: a list/numpy array of integers indicating the size of sets for observables\n",
    "        transition_mat: a K-by-K transition matrix for the latent Markov chain; if none, a tran_mat will be generated\n",
    "        sig: the parameter used for generating a transition matrix if transition_mat is not provided\n",
    "        ioi: if True, use ioi the scheme to sample two tokens from O_1 and repeat; otherwise uniformly sample tokens from O_1 independently\n",
    "        special_tokens: a 1d torch array of length 2. If not None, use the two tokens for generating IOI\n",
    "        return_states: if True, returns latent states\n",
    "        return_tokens_rep: if True, returns tokens that are being repeated for each seq\n",
    "    Returns:\n",
    "        data: a list containing variables for the HMM,\n",
    "        including input sequences, 2d torch.Tensor of type torch.long;\n",
    "        transition_mat (useful when it is being generated in the function);\n",
    "        if return_states is True, the latent states for each seq;\n",
    "        if return_tokens_rep is True, for IOI also return the tokens being repeated\n",
    "    \"\"\"\n",
    "    # check input arguments\n",
    "    vocab_size = vocab.size(0)\n",
    "    K = len(state_sizes)\n",
    "    K_total = np.sum(state_sizes)\n",
    "    size_cum = np.concatenate(([0], np.cumsum(state_sizes)))\n",
    "    assert (\n",
    "        np.all(state_sizes > 0) and K_total <= vocab_size\n",
    "    ), \"Wrong input for state_sizes\"\n",
    "    if transition_mat is not None:\n",
    "        m1, m2 = transition_mat.shape\n",
    "        assert (m1 == m2) and (\n",
    "            m1 == K\n",
    "        ), \"Incorrect input dimension of transition matrix\"\n",
    "        assert torch.all(transition_mat >= 0) and torch.all(\n",
    "            torch.abs(transition_mat.sum(dim=1) - 1) < 1e-6\n",
    "        ), \"Incorrect input of transition matrix\"\n",
    "    else:\n",
    "        transition_mat = gen_tran_mat(K, 1, sig=sig)\n",
    "    _, pi = calc_opt_err(transition_mat)  # get equilibrium distribution pi\n",
    "    pi = torch.Tensor(pi).float()\n",
    "    if return_tokens_rep:\n",
    "        assert ioi, \"ioi should be set to True\"\n",
    "\n",
    "    states = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    tokens_rep = torch.zeros(sample_size, 2).type(torch.LongTensor)\n",
    "    states[:, 0] = torch.multinomial(pi, sample_size, replacement=True)\n",
    "    for i in range(sample_size):\n",
    "        size = state_sizes[states[i, 0]]\n",
    "        data[i, 0] = size_cum[states[i, 0]] + torch.multinomial(\n",
    "            torch.ones(size) / size, 1\n",
    "        )\n",
    "        for j in range(max_seq_len - 1):\n",
    "            states[i, j + 1] = torch.multinomial(transition_mat[states[i, j], :], 1)\n",
    "            size = state_sizes[states[i, j + 1]]\n",
    "            data[i, j + 1] = size_cum[states[i, j + 1]] + torch.multinomial(\n",
    "                torch.ones(size) / size, 1\n",
    "            )\n",
    "        if ioi:\n",
    "            loc = states[i] == 0  # identify the state 0 for inserting repetition\n",
    "            to_repeat_len = (loc.sum() + 1) // 2\n",
    "            if special_tokens is None:\n",
    "                tokens = torch.multinomial(\n",
    "                    torch.ones(state_sizes[0]) / state_sizes[0],\n",
    "                    to_repeat_len,\n",
    "                    replacement=True,\n",
    "                )  # sample a sequence to repeat\n",
    "            else:\n",
    "                tokens_idx = torch.multinomial(\n",
    "                    torch.ones(len(special_tokens)) / len(special_tokens),\n",
    "                    to_repeat_len,\n",
    "                    replacement=True,\n",
    "                )\n",
    "                tokens = special_tokens[tokens_idx]\n",
    "            data[i, loc] = tokens.repeat(2)[: loc.sum()]\n",
    "            if return_tokens_rep:  # NOTE: buggy, set this to False\n",
    "                tokens_rep[i] = tokens\n",
    "\n",
    "    out = [data, transition_mat]\n",
    "    if return_states:\n",
    "        out.append(states)\n",
    "    if return_tokens_rep:\n",
    "        out.append(tokens_rep)\n",
    "    return out\n",
    "\n",
    "\n",
    "def gen_insert_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    background=\"random\",\n",
    "    background_random_weight=None,\n",
    "    pattern=\"aaa\",\n",
    "    insrt_num_tokens=5,\n",
    "    insrt_sep=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on different patterns.\n",
    "    Insert a short pattern in a purely random sequence (if background='random') or all-zero sequence\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        background: 'random' produces random sequence background, otherwise all-zero sequences\n",
    "        background_random_weight: probability weight for generating random background, default is uniform random\n",
    "        pattern: 'aaa' produces simple repetition pattern, 'random' produces a randomly sampled short pattern\n",
    "                1d torch.Tensor plants the specified pattern into background, otherwise do nothing\n",
    "        insrt_num_tokens: the number of tokens being planted\n",
    "        insrt_sep: the index difference between consecutive tokens that are planted\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long\n",
    "        pattern: the torch.Tensor pattern being sampled if pattern='aaa' or 'random'\n",
    "        pos_arr: 2d torch.Tensor, the indices of tokens planted in the sequences\n",
    "\n",
    "    \"\"\"\n",
    "    assert type(insrt_num_tokens) == int, \"insrt_num_tokens must be an odd integer\"\n",
    "    assert insrt_num_tokens % 2 == 1, \"insrt_num_tokens must be an odd integer\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    k = insrt_num_tokens // 2\n",
    "    if background_random_weight is None:  # uniform random noise in background\n",
    "        background_random_weight = torch.ones(vocab_size) / vocab_size\n",
    "\n",
    "    if background == \"random\":\n",
    "        data = torch.multinomial(\n",
    "            background_random_weight.repeat(sample_size, 1),\n",
    "            max_seq_len,\n",
    "            replacement=True,\n",
    "        )  # random background\n",
    "    else:\n",
    "        data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "\n",
    "    pos_arr = torch.zeros(sample_size, insrt_num_tokens)\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        insrt_pos_center = torch.randint(\n",
    "            k * insrt_sep, max_seq_len - k * insrt_sep, size=(1,)\n",
    "        )\n",
    "        insrt_pos = torch.arange(-k, k + 1) * insrt_sep + insrt_pos_center\n",
    "        insrt_pos.type(torch.LongTensor)\n",
    "        pos_arr[i, :] = insrt_pos\n",
    "        if pattern == \"aaa\":\n",
    "            pattern = torch.multinomial(torch.ones(vocab_size), 1).repeat(\n",
    "                insrt_num_tokens\n",
    "            )\n",
    "            data[i, insrt_pos] = vocab[pattern]  # plant a simple repetition patter\n",
    "        elif pattern == \"random\":\n",
    "            pattern = torch.multinomial(\n",
    "                torch.ones(vocab_size), insrt_num_tokens, replacement=True\n",
    "            )  # a random pattern\n",
    "            data[i, insrt_pos] = vocab[pattern]  # planted the pattern sampled earlier\n",
    "        elif torch.is_tensor(pattern):\n",
    "            data[i, insrt_pos] = vocab[\n",
    "                pattern\n",
    "            ]  # planted the pattern given by the argument\n",
    "        else:\n",
    "            pass  # do not plant signal, only has background\n",
    "\n",
    "    return data, pattern, pos_arr\n",
    "\n",
    "\n",
    "def gen_markov_data(\n",
    "    vocab, max_seq_len, sample_size, transition_mat, init_state_dist=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on a markov chain.\n",
    "    The markov chain is sampled according to a given transition matrix\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        transition_max: transition matrix for the Markov chain, a 2d torch.Tensor that has the same dimension\n",
    "                as the vocabulary size, must be a valid transition matrix\n",
    "        init_state_dist: the initial state distribution, 1d Tensor that sums to one\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    m1, m2 = transition_mat.shape\n",
    "    assert (m1 == m2) and (\n",
    "        m1 == vocab_size\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat >= 0) and torch.all(\n",
    "        torch.abs(transition_mat.sum(dim=1) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    if init_state_dist is not None:\n",
    "        assert (\n",
    "            torch.abs(init_state_dist.sum() - 1) < 1e-6\n",
    "        ), \"Incorrect input of initial state distribution: not summing to one\"\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    if (\n",
    "        init_state_dist is None\n",
    "    ):  # random initial states at position 0 and 1 for each sequence\n",
    "        data[:, 0] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "    else:  # use the initial state distribution if provided\n",
    "        states_init = torch.multinomial(init_state_dist, sample_size, replacement=True)\n",
    "        data[:, 0] = states_init\n",
    "    for i in range(sample_size):\n",
    "        for j in range(max_seq_len - 1):\n",
    "            data[i, j + 1] = torch.multinomial(transition_mat[data[i, j], :], 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_2nd_markov_data(\n",
    "    vocab, max_seq_len, sample_size, transition_mat, init_state_dist=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on a markov chain.\n",
    "    The markov chain is sampled according to a given transition matrix/tensor\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        transition_max: transition matrix for the Markov chain, a 3d torch.Tensor K * K * K where the last dimension is the\n",
    "                                    output probability; must be a valid transition matrix\n",
    "        init_state_dist: the initial state distribution, 1d Tensor that sums to one\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    m1, m2, m3 = transition_mat.shape\n",
    "    assert (\n",
    "        (m1 == m2) and (m1 == m3) and (m1 == vocab_size)\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat >= 0) and torch.all(\n",
    "        torch.abs(transition_mat.sum(dim=2) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    if init_state_dist is not None:\n",
    "        assert (\n",
    "            torch.abs(init_state_dist.sum() - 1) < 1e-6\n",
    "        ), \"Incorrect input of initial state distribution: not summing to one\"\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    if (\n",
    "        init_state_dist is None\n",
    "    ):  # random initial states at position 0 and 1 for each sequence\n",
    "        data[:, 0] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "        data[:, 1] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "    else:  # use the initial state distribution if provided\n",
    "        states_full = torch.multinomial(init_state_dist, sample_size, replacement=True)\n",
    "        data[:, 0] = states_full // vocab_size\n",
    "        data[:, 1] = states_full % vocab_size\n",
    "    for i in range(sample_size):\n",
    "        for j in range(max_seq_len - 2):\n",
    "            data[i, j + 2] = torch.multinomial(\n",
    "                transition_mat[data[i, j], data[i, j + 1], :], 1\n",
    "            )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_3rd_markov_data(\n",
    "    vocab, max_seq_len, sample_size, transition_mat, init_state_dist=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on a markov chain.\n",
    "    The markov chain is sampled according to a given transition matrix/tensor\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        transition_max: transition matrix for the Markov chain, a 4d torch.Tensor K * K * K where the last dimension is the\n",
    "                                    output probability; must be a valid transition matrix\n",
    "        init_state_dist: the initial state distribution, 1d Tensor that sums to one\n",
    "    Returns:\n",
    "        data: input sequences, 3d torch.Tensor of type torch.long\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    m1, m2, m3, m4 = transition_mat.shape\n",
    "    assert (\n",
    "        (m1 == m2) and (m1 == m3) and (m1 == m4) and (m1 == vocab_size)\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat >= 0) and torch.all(\n",
    "        torch.abs(transition_mat.sum(dim=3) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    if init_state_dist is not None:\n",
    "        assert (\n",
    "            torch.abs(init_state_dist.sum() - 1) < 1e-6\n",
    "        ), \"Incorrect input of initial state distribution: not summing to one\"\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    if (\n",
    "        init_state_dist is None\n",
    "    ):  # random initial states at position 0 and 1 for each sequence\n",
    "        data[:, 0] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "        data[:, 1] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "        data[:, 2] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "    else:  # use the initial state distribution if provided\n",
    "        states_full = torch.multinomial(init_state_dist, sample_size, replacement=True)\n",
    "        s0, s12 = states_full // (vocab_size**2), states_full % (vocab_size**2)\n",
    "        data[:, 0] = s0\n",
    "        data[:, 1] = s12 // vocab_size\n",
    "        data[:, 2] = s12 % vocab_size\n",
    "    for i in range(sample_size):\n",
    "        for j in range(max_seq_len - 3):\n",
    "            data[i, j + 3] = torch.multinomial(\n",
    "                transition_mat[data[i, j], data[i, j + 1], data[i, j + 2], :], 1\n",
    "            )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_mixed1st_markov_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    transition_mat,\n",
    "    transition_mat2,\n",
    "    init_state_dist=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on two markov chains.\n",
    "    Both markov chains are sampled according to the associated given transition matrices\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        transition_max: transition matrix for the Markov chain, a 2d torch.Tensor K * K where the second dimension is the\n",
    "                                    output probability; must be a valid transition matrix\n",
    "        transition_mat2: similar to transition_max, used to model long-range dependence\n",
    "        init_state_dist: the initial state distribution, 1d Tensor that sums to one\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    m1, m2 = transition_mat.shape\n",
    "    assert (m1 == m2) and (\n",
    "        m1 == vocab_size\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat >= 0) and torch.all(\n",
    "        torch.abs(transition_mat.sum(dim=1) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    m1, m2 = transition_mat2.shape\n",
    "    assert (m1 == m2) and (\n",
    "        m1 == vocab_size\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat2 >= 0) and torch.all(\n",
    "        torch.abs(transition_mat2.sum(dim=1) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    if init_state_dist is not None:\n",
    "        assert (\n",
    "            torch.abs(init_state_dist.sum() - 1) < 1e-6\n",
    "        ), \"Incorrect input of initial state distribution: not summing to one\"\n",
    "\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    if (\n",
    "        init_state_dist is None\n",
    "    ):  # random initial states at position 0 and 1 for each sequence\n",
    "        data[:, 0] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "    else:  # use the initial state distribution if provided\n",
    "        states_init = torch.multinomial(init_state_dist, sample_size, replacement=True)\n",
    "        data[:, 0] = states_init\n",
    "    for i in range(sample_size):\n",
    "        for j in range(max_seq_len - 1):\n",
    "            a = torch.bernoulli(torch.Tensor([0.3]))\n",
    "            token = torch.multinomial(transition_mat[data[i, j], :], 1)\n",
    "            token2 = (\n",
    "                torch.multinomial(transition_mat2[data[i, j - 9], :], 1)\n",
    "                if j > 8\n",
    "                else token\n",
    "            )\n",
    "            data[i, j + 1] = a * token + (1 - a) * token2\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_mixed2nd_markov_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    transition_mat,\n",
    "    transition_mat2,\n",
    "    init_state_dist=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on two markov chains.\n",
    "    Both markov chains are sampled according to the associated given transition matrix/tensor\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        transition_max: transition matrix for the Markov chain, a 3d torch.Tensor K * K * K where the last dimension is the\n",
    "                                    output probability; must be a valid transition matrix\n",
    "        transition_mat2: similar to transition_max, used to model long-range dependence\n",
    "        init_state_dist: the initial state distribution, 1d Tensor that sums to one\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    m1, m2, m3 = transition_mat.shape\n",
    "    assert (\n",
    "        (m1 == m2) and (m1 == m3) and (m1 == vocab_size)\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat >= 0) and torch.all(\n",
    "        torch.abs(transition_mat.sum(dim=2) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    m1, m2, m3 = transition_mat2.shape\n",
    "    assert (\n",
    "        (m1 == m2) and (m1 == m3) and (m1 == vocab_size)\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat2 >= 0) and torch.all(\n",
    "        torch.abs(transition_mat2.sum(dim=2) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    if init_state_dist is not None:\n",
    "        assert (\n",
    "            torch.abs(init_state_dist.sum() - 1) < 1e-6\n",
    "        ), \"Incorrect input of initial state distribution: not summing to one\"\n",
    "\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "    if (\n",
    "        init_state_dist is None\n",
    "    ):  # random initial states at position 0 and 1 for each sequence\n",
    "        data[:, 0] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "        data[:, 1] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "    else:  # use the initial state distribution if provided\n",
    "        states_full = torch.multinomial(init_state_dist, sample_size, replacement=True)\n",
    "        data[:, 0] = states_full // vocab_size\n",
    "        data[:, 1] = states_full % vocab_size\n",
    "    for i in range(sample_size):\n",
    "        for j in range(max_seq_len - 2):\n",
    "            a = torch.bernoulli(torch.Tensor([1 / 2]))\n",
    "            token = torch.multinomial(transition_mat[data[i, j], data[i, j + 1], :], 1)\n",
    "            token2 = (\n",
    "                torch.multinomial(transition_mat2[data[i, j - 9], data[i, j - 8], :], 1)\n",
    "                if j > 8\n",
    "                else token\n",
    "            )\n",
    "            data[i, j + 2] = a * token + (1 - a) * token2\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_higher_markov_data(\n",
    "    vocab, max_seq_len, sample_size, transition_mat, init_state_dist=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate input sequences for training/testing based on a higher markov chain,\n",
    "    which is constructed from a first-order transition probability matrix\n",
    "    Args:\n",
    "        vocab: 1d torch.Tensor containing entire vocabulary\n",
    "        max_seq_len: positive integer that specifies the maximum number of tokens in a sequence\n",
    "        sample_size: the number of input sequences\n",
    "        transition_max: transition matrix for the Markov chain, a 2d torch.Tensor K * K where the second dimension is the\n",
    "                                    output probability; must be a valid transition matrix\n",
    "        init_state_dist: the initial state distribution, 1d Tensor that sums to one\n",
    "    Returns:\n",
    "        data: input sequences, 2d torch.Tensor of type torch.long\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    m1, m2 = transition_mat.shape\n",
    "    assert (m1 == m2) and (\n",
    "        m1 == vocab_size\n",
    "    ), \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(transition_mat >= 0) and torch.all(\n",
    "        torch.abs(transition_mat.sum(dim=1) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "    data = torch.zeros(sample_size, max_seq_len).type(torch.LongTensor)\n",
    "\n",
    "    if (\n",
    "        init_state_dist is None\n",
    "    ):  # random initial states at position 0 and 1 for each sequence\n",
    "        data[:, 0] = torch.randint(0, vocab_size, size=(sample_size,))\n",
    "    else:\n",
    "        states_init = torch.multinomial(init_state_dist, sample_size, replacement=True)\n",
    "        data[:, 0] = states_init\n",
    "    for i in range(sample_size):\n",
    "        for j in range(max_seq_len - 1):\n",
    "            if j < 4:\n",
    "                data[i, j + 1] = torch.multinomial(transition_mat[data[i, j], :], 1)\n",
    "            else:\n",
    "                vec = torch.Tensor(\n",
    "                    [\n",
    "                        torch.mean((data[i, range(j - 4, j + 1)] == k) + 0.0)\n",
    "                        for k in range(vocab_size)\n",
    "                    ]\n",
    "                )\n",
    "                probs = torch.matmul(transition_mat.T, vec)\n",
    "                data[i, j + 1] = torch.multinomial(probs, 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_binary_random_pattern(vocab, max_seq_len, sample_size, probs=1 / 2):\n",
    "    \"\"\"\n",
    "    Generate two types of patterns randomly, which are mixed in the inputs\n",
    "    \"\"\"\n",
    "    vocab_size = vocab.size(0)\n",
    "    assert vocab_size >= 6, \"Need vocabulary size no smaller than 7\"\n",
    "\n",
    "    tmp = torch.bernoulli(probs * torch.ones(sample_size, max_seq_len // 4)).type(\n",
    "        torch.bool\n",
    "    )\n",
    "    tmp = torch.Tensor(np.repeat(tmp.numpy(), 4, axis=1)).bool()\n",
    "    seq1 = (\n",
    "        torch.Tensor([0, 2, 3, 5])\n",
    "        .repeat(sample_size, max_seq_len // 4)\n",
    "        .type(torch.long)\n",
    "    )\n",
    "    seq2 = (\n",
    "        torch.Tensor([1, 2, 3, 4])\n",
    "        .repeat(sample_size, max_seq_len // 4)\n",
    "        .type(torch.long)\n",
    "    )\n",
    "    data = torch.zeros(sample_size, max_seq_len).long()\n",
    "    data[tmp] = seq1[tmp]\n",
    "    data[~tmp] = seq2[~tmp]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_mixed_higher_markov_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    transition_mats=None,\n",
    "    max_order=2,\n",
    "    order_freq=None,\n",
    "    sig_param=None,\n",
    "    delimiter_freq=None,\n",
    "):\n",
    "    vocab_size = vocab.size(0)\n",
    "    delimiter_index_high = (\n",
    "        8  # insert delimiter after we generate at most break_index_high tokens\n",
    "    )\n",
    "    delimiter_index_low = 5\n",
    "    if order_freq is None:\n",
    "        order_freq = torch.ones(max_order) / max_order\n",
    "    if sig_param is None:\n",
    "        sig_param = torch.arange(max_order) + 1\n",
    "    if delimiter_freq is None:\n",
    "        freq = torch.ones(delimiter_index_high)\n",
    "        freq[: (delimiter_index_low + 1)] = 0\n",
    "        delimiter_freq = freq / freq.sum()\n",
    "\n",
    "    if transition_mats is None:  # generate transition matrix/tensor if no provided\n",
    "        transition_mats = [\n",
    "            torch.zeros(tuple([vocab_size - 1] * mc_order))\n",
    "            for mc_order in range(1, max_order + 1)\n",
    "        ]\n",
    "        for mc_order in range(1, max_order + 1):\n",
    "            mat = torch.exp(\n",
    "                sig_param[mc_order - 1]\n",
    "                * torch.randn(tuple([vocab_size - 1] * (mc_order + 1)))\n",
    "            )\n",
    "            transition_mats[mc_order - 1] = mat / mat.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    data = torch.zeros(sample_size, max_seq_len).long()\n",
    "    # uniform random initial states\n",
    "    data[:, :max_order] = torch.randint(\n",
    "        0, vocab_size - 1, size=(sample_size, max_order)\n",
    "    )\n",
    "    # sample next-token sequentially\n",
    "    for i in range(sample_size):\n",
    "        delimiter_index = torch.multinomial(delimiter_freq, 1)\n",
    "        mc_order = torch.multinomial(order_freq, 1) + 1\n",
    "        mat = transition_mats[mc_order - 1]\n",
    "        counter = 0\n",
    "        for j in range(max_seq_len - 1):\n",
    "            if counter <= delimiter_index:\n",
    "                counter += 1\n",
    "                states = data[\n",
    "                    i, range(j + 1 - mc_order, j + 1)\n",
    "                ].numpy()  # use the previous mc_order states to sample next token\n",
    "                if (\n",
    "                    vocab_size - 1 in states\n",
    "                ):  # if delimiter is in the states, look past to get one more token and remove delimiter\n",
    "                    states = data[i, range(j - mc_order, j + 1)].numpy()\n",
    "                    states = states[states != vocab_size - 1]\n",
    "                data[i, j + 1] = torch.multinomial(mat[tuple(states)], 1)\n",
    "            else:  # reach the index for delimiter, resample index and mc order, and add a delimiter token\n",
    "                delimiter_index = torch.multinomial(delimiter_freq, 1)\n",
    "                mc_order = torch.multinomial(order_freq, 1) + 1\n",
    "                mat = transition_mats[mc_order - 1]\n",
    "                counter = 0\n",
    "                data[i, j + 1] = torch.tensor(\n",
    "                    [vocab_size - 1]\n",
    "                ).long()  # add a delimiter token (index is vocab_size-1)\n",
    "    return data, transition_mats\n",
    "\n",
    "\n",
    "def gen_mixed_delimited_markov_data(\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    components=3,\n",
    "    transition_mats=None,\n",
    "    max_order=2,\n",
    "    component_freq=None,\n",
    "    sig_param=None,\n",
    "    delimiter_freq=None,\n",
    "):\n",
    "    vocab_size = vocab.size(0)\n",
    "    delimiter_index_high = (\n",
    "        8  # insert delimiter after we generate at most break_index_high tokens\n",
    "    )\n",
    "    delimiter_index_low = 5\n",
    "    if component_freq is None:\n",
    "        component_freq = torch.ones(components) / components\n",
    "    if sig_param is None:\n",
    "        sig_param = torch.arange(components) + 1\n",
    "    if delimiter_freq is None:\n",
    "        freq = torch.ones(delimiter_index_high)\n",
    "        freq[: (delimiter_index_low + 1)] = 0\n",
    "        delimiter_freq = freq / freq.sum()\n",
    "\n",
    "    if transition_mats is None:  # generate transition matrix/tensor if no provided\n",
    "        transition_mats = [\n",
    "            torch.zeros(tuple([vocab_size - 1] * max_order)) for k in range(components)\n",
    "        ]\n",
    "        for k in range(components):\n",
    "            mat = torch.exp(\n",
    "                sig_param[k] * torch.randn(tuple([vocab_size - 1] * (max_order + 1)))\n",
    "            )\n",
    "            transition_mats[k] = mat / mat.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    data = torch.zeros(sample_size, max_seq_len).long()\n",
    "    # uniform random initial states\n",
    "    data[:, :max_order] = torch.randint(\n",
    "        0, vocab_size - 1, size=(sample_size, max_order)\n",
    "    )\n",
    "    # sample next-token sequentially\n",
    "    for i in range(sample_size):\n",
    "        delimiter_index = torch.multinomial(delimiter_freq, 1)\n",
    "        k = torch.multinomial(component_freq, 1)\n",
    "        mat = transition_mats[k]\n",
    "        counter = 0\n",
    "        for j in range(max_seq_len - 1):\n",
    "            if counter <= delimiter_index:\n",
    "                counter += 1\n",
    "                states = data[\n",
    "                    i, range(j + 1 - max_order, j + 1)\n",
    "                ].numpy()  # use the previous max_order states to sample next token\n",
    "                if (\n",
    "                    vocab_size - 1 in states\n",
    "                ):  # if delimiter is in the states, just do random sampling\n",
    "                    data[i, j + 1] = torch.randint(0, vocab_size - 1, size=(1,))\n",
    "            else:  # reach the index for delimiter, resample index and mc order, and add a delimiter token\n",
    "                delimiter_index = torch.multinomial(delimiter_freq, 1)\n",
    "                k = torch.multinomial(component_freq, 1)\n",
    "                mat = transition_mats[k]\n",
    "                counter = 0\n",
    "                data[i, j + 1] = torch.tensor(\n",
    "                    [vocab_size - 1]\n",
    "                ).long()  # add a delimiter token (index is vocab_size-1)\n",
    "    return data, transition_mats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration\n",
    "Set up training hyperparameters, and optimization settings including SAM optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(src, lens, starts=None, ignore_segment=0, ignore_burning=0):\n",
    "    M = torch.ones_like(src)\n",
    "    if lens is not None and starts is None:\n",
    "        M = torch.Tensor(\n",
    "            mask_get_along_axis(\n",
    "                src.shape,\n",
    "                lens,\n",
    "                ignore_segment=ignore_segment,\n",
    "                ignore_burning=ignore_burning,\n",
    "            )\n",
    "        )\n",
    "    elif lens is not None and starts is not None:\n",
    "        M = torch.Tensor(\n",
    "            mask_get_given_starts(\n",
    "                src.shape,\n",
    "                lens,\n",
    "                starts,\n",
    "                ignore_segment=ignore_segment,\n",
    "                ignore_burning=ignore_burning,\n",
    "            )\n",
    "        )\n",
    "    return M\n",
    "\n",
    "\n",
    "def get_loss(model, criterion, src):\n",
    "    output = model(src)\n",
    "    vocab_size = output.size(-1)\n",
    "    loss = criterion(\n",
    "        output[:, :-1].contiguous().view(-1, vocab_size),\n",
    "        src[:, 1:].contiguous().view(-1),\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def loss_err(model, criterion, src, mask):\n",
    "    model.eval()\n",
    "    output = model(src)\n",
    "    vocab_size = output.size(-1)\n",
    "    loss = criterion(\n",
    "        output[:, :-1].contiguous().view(-1, vocab_size),\n",
    "        src[:, 1:].contiguous().view(-1),\n",
    "    )\n",
    "\n",
    "    tmp = output.argmax(dim=2)[:, :-1] == src[:, 1:]\n",
    "    err = 1 - torch.sum(tmp.cpu() * mask[:, :-1], dtype=torch.float) / torch.sum(mask)\n",
    "    return loss, err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_simulated_data(\n",
    "    distr,\n",
    "    vocab,\n",
    "    max_seq_len,\n",
    "    sample_size,\n",
    "    regime,\n",
    "    pool_size,\n",
    "    patterns,\n",
    "    rep_l,\n",
    "    rep_h,\n",
    "    device,\n",
    "):\n",
    "    if regime == \"simple repetition\":\n",
    "        src, lens = gen_simple_data(\n",
    "            vocab,\n",
    "            max_seq_len,\n",
    "            sample_size,\n",
    "            return_lens=True,\n",
    "            rep_l=rep_l,\n",
    "            rep_h=rep_h,\n",
    "        )\n",
    "\n",
    "        return src.to(device), lens, None, None\n",
    "\n",
    "    elif regime == \"varied repetition\":\n",
    "        src, lens, starts, patterns = gen_repetition_data(\n",
    "            vocab,\n",
    "            max_seq_len,\n",
    "            sample_size,\n",
    "            distr=distr,\n",
    "            pattern_pool_size=pool_size,\n",
    "            patterns=patterns,\n",
    "            return_lens=True,\n",
    "            rep_l=rep_l,\n",
    "            rep_h=rep_h,\n",
    "        )\n",
    "\n",
    "        return src.to(device), lens, starts, patterns\n",
    "    \n",
    "    elif regime == \"modular addition\":\n",
    "        src, lens, starts, patterns = gen_mod_add_data(\n",
    "            vocab,\n",
    "            max_seq_len,\n",
    "            sample_size,\n",
    "            distr=distr,\n",
    "            pattern_pool_size=pool_size,\n",
    "            patterns=patterns,\n",
    "            return_lens=True,\n",
    "            rep_l=rep_l,\n",
    "            rep_h=rep_h,\n",
    "        )\n",
    "\n",
    "        return src.to(device), lens, starts, patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_distr(config):\n",
    "    if config.distr == \"two-level\":\n",
    "        p = np.concatenate(\n",
    "            (\n",
    "                np.array([1 / 8] * 4),\n",
    "                np.array([1 / (2 * (config.vocab_size - 4))] * (config.vocab_size - 4)),\n",
    "            )\n",
    "        )\n",
    "        # np.random.shuffle(p)\n",
    "        p = torch.Tensor(p)\n",
    "    elif config.distr == \"two-level-3\":  # NOT USED for now, may change later\n",
    "        p = np.concatenate(\n",
    "            (\n",
    "                np.array([1 / 8] * 4),\n",
    "                np.array([1 / (2 * (config.vocab_size - 4))] * (config.vocab_size - 4)),\n",
    "            )\n",
    "        )\n",
    "        # np.random.shuffle(p)\n",
    "        p = torch.Tensor(p)\n",
    "    elif config.distr == \"zipf\":\n",
    "        # https://en.wikipedia.org/wiki/Zipf%27s_law\n",
    "        p = np.array([1 / (i + 2.7) for i in range(1, config.vocab_size + 1)])\n",
    "        p = p / np.sum(p)\n",
    "        # np.random.shuffle(p)\n",
    "        p = torch.Tensor(p)\n",
    "    elif config.distr == \"unif\":\n",
    "        p = None\n",
    "    else:\n",
    "        raise ValueError(f\"distr {config.distr} is not supported!\")\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_infinite(\n",
    "    model,\n",
    "    config,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    use_sam = False,\n",
    "):\n",
    "    num_epoch = config.num_epoch\n",
    "    batch_size = config.batch_size\n",
    "    vocab = torch.arange(config.vocab_size).type(torch.LongTensor)\n",
    "    p = make_distr(config)\n",
    "\n",
    "    src_test, lens_test, starts_test, patterns = gen_simulated_data(\n",
    "        distr=p,\n",
    "        vocab=vocab,\n",
    "        max_seq_len=config.max_seq_len,\n",
    "        regime=config.regime,\n",
    "        sample_size=config.sample_size_test,\n",
    "        pool_size=config.pool_size,\n",
    "        patterns=None,\n",
    "        rep_l=config.rep_l,\n",
    "        rep_h=config.rep_h,\n",
    "        device=config.device,\n",
    "    )\n",
    "\n",
    "    src_test_ood, lens_test_ood, starts_test_ood, _ = gen_simulated_data(\n",
    "        distr=None,\n",
    "        vocab=vocab,\n",
    "        max_seq_len=config.max_seq_len,\n",
    "        regime=config.regime,\n",
    "        sample_size=config.sample_size_test,\n",
    "        pool_size=None,\n",
    "        patterns=None,\n",
    "        rep_l=config.ood_len_pattern,\n",
    "        rep_h=config.ood_len_pattern + 1,\n",
    "        device=config.device,\n",
    "    )\n",
    "\n",
    "    M_test = get_mask(\n",
    "        src_test,\n",
    "        lens_test,\n",
    "        starts_test,\n",
    "        ignore_segment=config.ignore_segment,\n",
    "        ignore_burning=config.ignore_burning,\n",
    "    )\n",
    "    M_test_ood = get_mask(\n",
    "        src_test_ood,\n",
    "        lens_test_ood,\n",
    "        starts_test_ood,\n",
    "        ignore_segment=config.ignore_segment,\n",
    "        ignore_burning=config.ignore_burning,\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        [src_test, lens_test, starts_test], os.path.join(config.out_dir, \"test.pth\")\n",
    "    )\n",
    "    torch.save(\n",
    "        [src_test_ood, lens_test_ood, starts_test_ood],\n",
    "        os.path.join(config.out_dir, \"test_ood.pth\"),\n",
    "    )\n",
    "\n",
    "    err_arr = np.zeros((num_epoch, 6))\n",
    "    sharpness_arr = np.zeros((num_epoch,))\n",
    "    trial_sharpness_arr = np.zeros((num_epoch, 2000))\n",
    "    diff_by_blk_summary = dict()\n",
    "\n",
    "    err_arr_json = []\n",
    "    criterion = (\n",
    "        nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        if config.label_smoothing\n",
    "        else nn.CrossEntropyLoss()\n",
    "    )\n",
    "\n",
    "\n",
    "    train_dataset = []\n",
    "    for epoch in range(num_epoch):\n",
    "        src, lens_train, starts_train, _ = gen_simulated_data(\n",
    "            distr=p,\n",
    "            vocab=vocab,\n",
    "            max_seq_len=config.max_seq_len,\n",
    "            regime=config.regime,\n",
    "            sample_size=batch_size,\n",
    "            pool_size=config.pool_size,\n",
    "            patterns=patterns,\n",
    "            rep_l=config.rep_l,\n",
    "            rep_h=config.rep_h,\n",
    "            device=config.device,\n",
    "        )\n",
    "        M = get_mask(\n",
    "            src,\n",
    "            lens_train,\n",
    "            starts_train,\n",
    "            ignore_segment=config.ignore_segment,\n",
    "            ignore_burning=config.ignore_burning,\n",
    "        )\n",
    "        train_dataset.append((src, lens_train, starts_train, _, M))\n",
    "\n",
    "    # torch.save(train_dataset, \"train_dataset.pt\")\n",
    "\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src, lens_train, starts_train, _, M = train_dataset[epoch]\n",
    "\n",
    "        '''\n",
    "        src, lens_train, starts_train, _ = gen_simulated_data(\n",
    "            distr=p,\n",
    "            vocab=vocab,\n",
    "            max_seq_len=config.max_seq_len,\n",
    "            regime=config.regime,\n",
    "            sample_size=batch_size,\n",
    "            pool_size=config.pool_size,\n",
    "            patterns=patterns,\n",
    "            rep_l=config.rep_l,\n",
    "            rep_h=config.rep_h,\n",
    "            device=config.device,\n",
    "        )\n",
    "        M = get_mask(\n",
    "            src,\n",
    "            lens_train,\n",
    "            starts_train,\n",
    "            ignore_segment=config.ignore_segment,\n",
    "            ignore_burning=config.ignore_burning,\n",
    "        )\n",
    "        '''\n",
    "        loss = get_loss(model, criterion, src)\n",
    "        loss.backward()\n",
    "        \n",
    "        if use_sam:\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                loss = get_loss(model, criterion, src)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            loss = optimizer.step(closure)\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()  # useful if dropout or batchnorm etc is turned on\n",
    "            loss_train, train_err = loss_err(model, criterion, src, M)\n",
    "            loss_test, test_err = loss_err(model, criterion, src_test, M_test)\n",
    "            loss_test_ood, test_err_ood = loss_err(\n",
    "                model, criterion, src_test_ood, M_test_ood\n",
    "            )\n",
    "            if False: # compute full Hessian\n",
    "                hessian_train = get_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                sharpness = torch.trace(hessian_train)\n",
    "                print(sharpness)\n",
    "\n",
    "\n",
    "        if False: # compute block-diagonal Hessian\n",
    "            if (epoch % 100 == 0 and 1000 <= epoch <= 2000) or epoch in [0,700]:\n",
    "                blkdiag_hessian_train = get_blkdiag_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                avg_sharpness = sum([torch.trace(h) for h in blkdiag_hessian_train])\n",
    "                blk_spectrums = [torch.linalg.eigh(h)[0] for h in blkdiag_hessian_train]\n",
    "                # spectrum = torch.concat(blk_spectrums)\n",
    "                \n",
    "                # plot spectrum\n",
    "                parameter_names = [name for name, _ in model.named_parameters()]\n",
    "                plot_blk_spectrum(\n",
    "                   blk_spectrums, \n",
    "                   parameter_names, \n",
    "                   fig_name=f\"spectrum_epoch_{epoch}\", \n",
    "                   save_dir=config.out_dir\n",
    "                )\n",
    "\n",
    "                import matplotlib.pyplot as plt\n",
    "                spectrum = torch.concat(blk_spectrums)\n",
    "                plt.figure()\n",
    "                plt.hist(spectrum, 100)\n",
    "                plt.yscale('log')\n",
    "                plt.savefig(os.path.join(config.out_dir, f\"spectrum_hist_epoch_{epoch}\"))\n",
    "\n",
    "        if False: # directly compute Hessian trace\n",
    "            if epoch % 1000 == 0: # (epoch % 100 == 0 and 1000 <= epoch <= 2000) or epoch in [0,700]:\n",
    "                sharpness_trace = get_trace_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                avg_sharpness = sum(sharpness_trace) / len(sharpness_trace)\n",
    "                \n",
    "                # scale the sharpness by model weight\n",
    "                # avg_sharpness *= sum([torch.norm(p).item()**2 for p in model.parameters()])\n",
    "\n",
    "        if False:\n",
    "            if epoch % config.sharpness_step == 0:\n",
    "                avg_sharpness, diff_by_blk = get_robustness_blk(model, criterion, src=src, dataset=train_dataset, num_perturb=100, r_perturb=1e-3, data_sample_size=20, config=config)\n",
    "\n",
    "        if False:\n",
    "            if epoch % config.sharpness_step == 0:\n",
    "                diff = get_robustness(model, criterion, src=src, dataset=train_dataset, num_perturb=100, r_perturb=1e-3, data_sample_size=20, config=config)\n",
    "                avg_sharpness = sum(diff) / len(diff)\n",
    "\n",
    "        if config.sharpness_task == \"outer-product-Hessian\":\n",
    "            if epoch % config.sharpness_step == 0 and epoch > 9997:\n",
    "                H_out = get_outer_product_hess(model, criterion, src=src, dataset=train_dataset)\n",
    "                H = get_blkdiag_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                torch.save((H_out, H), f\"out/out-hess-{epoch}.pt\")\n",
    "\n",
    "        if config.sharpness_task == \"outer-product-Hessian-decompose\":\n",
    "            if epoch % config.sharpness_step == 0 and epoch > 5997:\n",
    "                H_out = get_outer_product_hess_decompose(model, criterion, src=src, dataset=train_dataset)\n",
    "                H = get_blkdiag_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                torch.save((H_out, H), f\"out/out-hess-decompose-{epoch}.pt\")\n",
    "\n",
    "        if config.sharpness_task == \"outer-product-Hessian-random-alignment\":\n",
    "            if 2 < epoch < 10:\n",
    "                # random model\n",
    "                state_dict = model.state_dict().copy()\n",
    "                for name in model.state_dict():\n",
    "                    state_dict[name] = torch.randn_like(model.state_dict()[name]) / math.sqrt(config.d_model)\n",
    "                model.load_state_dict(state_dict)\n",
    "                H_out = get_outer_product_hess_decompose(model, criterion, src=src, dataset=train_dataset)\n",
    "                H = get_blkdiag_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                torch.save((H_out, H), f\"out/out-hess-random-{epoch}.pt\")\n",
    "\n",
    "                # aligned model\n",
    "                state_dict = model.state_dict().copy()\n",
    "                for name in model.state_dict():\n",
    "                    if name not in ['h.1.mha.W_q.weight', 'h.1.mha.W_k.weight']:\n",
    "                        state_dict[name] = torch.randn_like(model.state_dict()[name]) / math.sqrt(config.d_model)\n",
    "                    else:\n",
    "                        if name == 'h.1.mha.W_q.weight':\n",
    "                            rot, _ = torch.linalg.qr(torch.randn_like(model.state_dict()[name]))\n",
    "                            state_dict[name] = torch.linalg.inv(state_dict['h.0.mha.W_o.weight'] @ state_dict['h.0.mha.W_v.weight'].T) @ rot\n",
    "                        else:\n",
    "                            state_dict[name] = rot\n",
    "                model.load_state_dict(state_dict)\n",
    "                H_out = get_outer_product_hess_decompose(model, criterion, src=src, dataset=train_dataset)\n",
    "                H = get_blkdiag_hessian(model, criterion, src=src, dataset=train_dataset)\n",
    "                torch.save((H_out, H), f\"out/out-hess-align-{epoch}.pt\")\n",
    "            elif epoch >= 10:\n",
    "                exit()\n",
    "\n",
    "\n",
    "        '''\n",
    "        if len(diff_by_blk_summary) == 0:\n",
    "            for k in diff_by_blk.keys():\n",
    "                diff_by_blk_summary[k] = [diff_by_blk[k].item()]\n",
    "        else:\n",
    "            for k in diff_by_blk.keys():\n",
    "                diff_by_blk_summary[k].append(diff_by_blk[k].item())\n",
    "        '''\n",
    "\n",
    "        #sharpness_arr[epoch] = avg_sharpness\n",
    "        #trial_sharpness_arr[epoch] = np.array([d.item() for d in diff])\n",
    "\n",
    "        err_arr[epoch, :] = [\n",
    "            loss_train.item(),\n",
    "            train_err.item(),\n",
    "            loss_test.item(),\n",
    "            test_err.item(),\n",
    "            loss_test_ood.item(),\n",
    "            test_err_ood.item(),\n",
    "        ]\n",
    "\n",
    "        err_arr_json += [\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"loss_train\": loss_train.item(),\n",
    "                \"err_train\": train_err.item(),\n",
    "                \"loss_test\": loss_test.item(),\n",
    "                \"err_test\": test_err.item(),\n",
    "                \"loss_ood\": loss_test_ood.item(),\n",
    "                \"err_ood\": test_err_ood.item(),\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % config.plot_attn_every_epoch == 0 and err_arr[epoch, 5] > 0.05:\n",
    "            plots_maker(\n",
    "                model,\n",
    "                config,\n",
    "                [src, src_test, src_test_ood],\n",
    "                epoch=epoch,\n",
    "                lens=[lens_train, lens_test, lens_test_ood],\n",
    "                starts=[starts_train, starts_test, starts_test_ood],\n",
    "                save_dir=os.path.join(config.out_dir, \"figures\"),\n",
    "            )\n",
    "\n",
    "            if config.print_output:\n",
    "                print(\n",
    "                    f\"----> Epoch: {epoch+1:>5}, Train Loss: {loss.item():.3f}, Test Error: {err_arr[epoch,3]:.3f}, OOD Error: {err_arr[epoch,5]:.3f}\"\n",
    "                )\n",
    "\n",
    "        if (1 + epoch) % (config.num_epoch // config.n_save) == 0 or (\n",
    "            config.up_to_first_save\n",
    "            and (1 + epoch)\n",
    "            in [\n",
    "                np.power(2, k)\n",
    "                for k in range(int(np.log2(config.num_epoch // config.n_save)))\n",
    "            ]\n",
    "        ):\n",
    "            out_path = os.path.join(config.out_dir, f\"ckpt_{epoch + 1}.pt\")\n",
    "            torch.save(model.state_dict(), out_path)\n",
    "\n",
    "    lens = [lens_train, lens_test, lens_test_ood]\n",
    "    _ = plot_err_over_pos(\n",
    "        model,\n",
    "        [src, src_test, src_test_ood],\n",
    "        config.vocab_size,\n",
    "        \"err_over_pos\",\n",
    "        lens=lens,\n",
    "        starts=[starts_train, starts_test, starts_test_ood],\n",
    "        src_labels=[\"train\", \"test\", \"ood\"],\n",
    "        save_dir=config.out_dir,\n",
    "    )\n",
    "\n",
    "    # np.save(\"out/trial_diff.npy\", trial_sharpness_arr)\n",
    "\n",
    "    return model, err_arr, err_arr_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "################# Simple utitlity function  ###################\n",
    "#####################################################\n",
    "\n",
    "\n",
    "def create_folder(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def fix_random_seed(seed, reproduce=False):\n",
    "    # cudnn.enabled = True\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "    if reproduce:\n",
    "        cudnn.benchmark = False\n",
    "        cudnn.deterministic = True\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        ## NOTE: uncomment for CUDA >= 10.2\n",
    "        # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "        ## NOTE: uncomment for pytorch >= 1.8\n",
    "        # torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    # os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    rng = torch.manual_seed(seed)\n",
    "\n",
    "    return rng\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "def gen_tran_mat(vocab_size, order, sig=1, sparsity=None):\n",
    "    mat = torch.exp(sig * torch.randn(tuple([vocab_size] * (order + 1))))\n",
    "    mat = mat / mat.sum(dim=-1, keepdim=True)\n",
    "    if sparsity is not None:\n",
    "        cutoff = torch.quantile(mat.flatten(), 1 - sparsity)\n",
    "        mat[mat < cutoff] = 0\n",
    "        mat = mat / mat.sum(dim=-1, keepdim=True)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def calc_opt_err(mat):\n",
    "    \"\"\"\n",
    "    Given a transition probability matrix in a Markov chain, calculate the optimal achievable error\n",
    "    Args:\n",
    "        mat: the transition probability matrix, will check its validity\n",
    "    Returns:\n",
    "        err_opt: scalar, the optimal error under equilibrium distribution\n",
    "        pi: 1d array, equilibrium distribution\n",
    "    \"\"\"\n",
    "\n",
    "    m = mat.size(0)\n",
    "    m1, m2 = mat.shape\n",
    "    assert m1 == m2, \"Incorrect input dimension of transition matrix\"\n",
    "    assert torch.all(mat >= 0) and torch.all(\n",
    "        torch.abs(mat.sum(dim=1) - 1) < 1e-6\n",
    "    ), \"Incorrect input of transition matrix\"\n",
    "\n",
    "    vals, vecs = np.linalg.eig(mat.numpy().T)\n",
    "    idx = np.argsort(vals)\n",
    "    pi = np.real(vecs[:, idx[-1]])  # equilibrium distribution\n",
    "    pi = pi / np.sum(pi)  # don't forget to normalize so that it sums to one\n",
    "    err_opt = np.dot(pi, 1 - mat.max(dim=1)[0].numpy())\n",
    "\n",
    "    return err_opt, pi\n",
    "\n",
    "\n",
    "def get_mat_full(mat, order=2):\n",
    "    \"\"\"\n",
    "    For second-order or third-order markov chains, get_mat_full will\n",
    "    1) if order=2, convert the transition matrix from the tensor form K*K*K to the matrix form (K^2) * (K^2)\n",
    "    2) if order=3, convert the transition matrix from the tensor form K*K*K*K to the matrix form (K^3) * (K^3)\n",
    "    Args:\n",
    "        mat: the transition probability tensor, will check its validity\n",
    "    Returns:\n",
    "        mat_full:  transition probability matrix\n",
    "    \"\"\"\n",
    "    if order == 2:\n",
    "        m1, m2, m3 = mat.shape\n",
    "        vocab_size = m1\n",
    "        assert (m1 == m2) and (\n",
    "            m1 == m3\n",
    "        ), \"Incorrect input dimension of transition matrix\"\n",
    "        assert torch.all(mat >= 0) and torch.all(\n",
    "            torch.abs(mat.sum(dim=2) - 1) < 1e-6\n",
    "        ), \"Incorrect input of transition matrix\"\n",
    "        mat_full = torch.zeros(vocab_size**2, vocab_size**2).float()\n",
    "        for k1 in range(vocab_size):\n",
    "            for k2 in range(vocab_size):\n",
    "                k = k1 * vocab_size + k2\n",
    "                k_out = k2 * vocab_size + torch.arange(vocab_size).long()\n",
    "                mat_full[k, k_out] = mat[k1, k2, :]\n",
    "    elif order == 3:\n",
    "        m1, m2, m3, m4 = mat.shape\n",
    "        vocab_size = m1\n",
    "        assert (\n",
    "            (m1 == m2) and (m1 == m3) and (m1 == m4)\n",
    "        ), \"Incorrect input dimension of transition matrix\"\n",
    "        assert torch.all(mat >= 0) and torch.all(\n",
    "            torch.abs(mat.sum(dim=3) - 1) < 1e-6\n",
    "        ), \"Incorrect input of transition matrix\"\n",
    "        mat_full = torch.zeros(vocab_size**3, vocab_size**3).float()\n",
    "        for k1 in range(vocab_size):\n",
    "            for k2 in range(vocab_size):\n",
    "                for k3 in range(vocab_size):\n",
    "                    k = k1 * (vocab_size**2) + k2 * vocab_size + k3\n",
    "                    k_out = (\n",
    "                        k2 * (vocab_size**2)\n",
    "                        + k3 * vocab_size\n",
    "                        + torch.arange(vocab_size).long()\n",
    "                    )\n",
    "                    mat_full[k, k_out] = mat[k1, k2, k3, :]\n",
    "    else:\n",
    "        warnings.warn(\"The order argument receives an incorrect input.\")\n",
    "\n",
    "    return mat_full\n",
    "\n",
    "\n",
    "def mask_get_along_axis(shape, indices):\n",
    "    assert shape[0] == len(\n",
    "        indices\n",
    "    ), \"length of indices show match number of rows in shape\"\n",
    "    mask = np.zeros(shape)\n",
    "    return np.array(\n",
    "        [\n",
    "            np.concatenate((np.zeros(indices[i]), np.ones(shape[1] - indices[i])))\n",
    "            for i in range(len(indices))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def mask_get_given_starts(shape, lens, starts, ignore_segment=0, ignore_burning=0):\n",
    "    n, L = shape[0], shape[1]\n",
    "    n1 = len(lens)\n",
    "    n2, rep = starts.shape\n",
    "    assert n == n1 and n == n2, \"Wrong input shapes\"\n",
    "    mask = np.zeros((n, L), dtype=int)\n",
    "    for i in range(n):\n",
    "        for j in range(ignore_segment, rep):\n",
    "            mask[i, (starts[i, j] + ignore_burning) : (starts[i, j] + lens[i])] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "#####################################################\n",
    "##################### Making plots ######################\n",
    "#####################################################\n",
    "\n",
    "\n",
    "def plot_err_curve(\n",
    "    err_arr,\n",
    "    setting_params=None,\n",
    "    fig_name=None,\n",
    "    save_dir=None,\n",
    "    opt_err=None,\n",
    "    plot_ood=False,\n",
    "    plot_train=True,\n",
    "    log_training_time=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    A simple function to make plots based on err_arr, optionally saving plots in the specified folder\n",
    "    Args:\n",
    "        err_arr: a numpy array of size num_epoch-by-6, containing train/test/ood-test loss/errors\n",
    "        setting_params: a dictionary containing setting parameters such as vocab_size, max_seq_len\n",
    "        opt_err: a optional 1d array showing the optimal achievable error\n",
    "        plot_ood: if true, plots the loss/error curces for ood test data\n",
    "    \"\"\"\n",
    "    num_epoch = (\n",
    "        setting_params[\"num_epoch\"] if setting_params is not None else err_arr.shape[0]\n",
    "    )\n",
    "    if fig_name is not None:\n",
    "        if save_dir is None:\n",
    "            if not os.path.isdir(\"Figs\"):\n",
    "                os.mkdir(\"Figs\")\n",
    "            save_path = os.path.join(\"Figs\", fig_name)\n",
    "        else:\n",
    "            save_path = os.path.join(save_dir, fig_name)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    if plot_train:\n",
    "        axs[0].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 0],\n",
    "            linewidth=2,\n",
    "            label=\"train loss\",\n",
    "        )\n",
    "    axs[0].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 2], linewidth=2, label=\"test loss\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[0].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 4],\n",
    "            linewidth=2,\n",
    "            label=\"ood test loss\",\n",
    "        )\n",
    "    axs[0].set_yscale(\"log\")\n",
    "    axs[0].set_title(\n",
    "        f\"Train/test loss, last/best test epoch {err_arr[-1,1]:.3f}, {np.min(err_arr[:,1]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[0].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    if plot_train:\n",
    "        axs[1].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 1],\n",
    "            linewidth=2,\n",
    "            label=\"train err\",\n",
    "        )\n",
    "    axs[1].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 3], linewidth=2, label=\"test err\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[1].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 5],\n",
    "            linewidth=2,\n",
    "            label=\"ood test err\",\n",
    "        )\n",
    "    if opt_err is not None:\n",
    "        axs[1].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            np.repeat(opt_err, num_epoch),\n",
    "            linestyle=\"dashed\",\n",
    "            label=\"optimal err\",\n",
    "        )\n",
    "    axs[1].legend()\n",
    "    axs[1].set_title(\n",
    "        f\"Train/test error, last/best test epoch {err_arr[-1,3]:.3f}, {np.min(err_arr[:,3]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[1].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    # axs[1].axhline(y=0.5, xmin=0, xmax=num_epoch, linestyle=\"dashed\", c=\"black\")\n",
    "\n",
    "    if log_training_time:\n",
    "        axs[0].set_xscale(\"log\")\n",
    "        axs[1].set_xscale(\"log\")\n",
    "\n",
    "    if fig_name is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "def plot_blk_spectrum(\n",
    "    spectrum_list,\n",
    "    param_names,\n",
    "    fig_name=None,\n",
    "    save_dir=None,\n",
    "):\n",
    "    if fig_name is not None:\n",
    "        if save_dir is None:\n",
    "            if not os.path.isdir(\"Figs\"):\n",
    "                os.mkdir(\"Figs\")\n",
    "            save_path = os.path.join(\"Figs\", fig_name)\n",
    "        else:\n",
    "            save_path = os.path.join(save_dir, fig_name)\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(12, 8))\n",
    "    plt.tight_layout()\n",
    "    for idx, spec in enumerate(spectrum_list):\n",
    "        col = idx % 5\n",
    "        row = idx // 5\n",
    "        axs[row][col].bar(np.arange(len(spec)), spec)\n",
    "        axs[row][col].set_title(f\"{param_names[idx]}\")\n",
    "    if fig_name is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "def plot_sharpness_curve(\n",
    "    sharpness_arr,\n",
    "    setting_params=None,\n",
    "    fig_name=None,\n",
    "    save_dir=None,\n",
    "):\n",
    "    num_epoch = (\n",
    "        setting_params[\"num_epoch\"] if setting_params is not None else sharpness_arr.shape[0]\n",
    "    )\n",
    "    if fig_name is not None:\n",
    "        if save_dir is None:\n",
    "            if not os.path.isdir(\"Figs\"):\n",
    "                os.mkdir(\"Figs\")\n",
    "            save_path = os.path.join(\"Figs\", fig_name)\n",
    "        else:\n",
    "            save_path = os.path.join(save_dir, fig_name)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(sharpness_arr)\n",
    "    if fig_name is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "def plot_err_curve_hmm(\n",
    "    err_arr,\n",
    "    setting_params=None,\n",
    "    fig_name=None,\n",
    "    save_dir=None,\n",
    "    opt_err=None,\n",
    "    plot_ood=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    A simple function to make plots based on err_arr. Similar to plot_err_curve, but also plots errors based on hmm\n",
    "    Args:\n",
    "        err_arr: a numpy array of size num_epoch-by-9, containing train/test/ood-test loss/errors, and IOI train/test/ood-test errors\n",
    "        setting_params: a dictionary containing setting parameters such as vocab_size, max_seq_len\n",
    "        opt_err: a optional 1d array showing the optimal achievable error\n",
    "        plot_ood: if true, plots the loss/error curces for ood test data\n",
    "    \"\"\"\n",
    "    num_epoch = (\n",
    "        setting_params[\"num_epoch\"] if setting_params is not None else err_arr.shape[0]\n",
    "    )\n",
    "    if fig_name is not None:\n",
    "        if save_dir is None:\n",
    "            if not os.path.isdir(\"Figs\"):\n",
    "                os.mkdir(\"Figs\")\n",
    "            save_path = os.path.join(\"Figs\", fig_name)\n",
    "        else:\n",
    "            save_path = os.path.join(save_dir, fig_name)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(3 * 6, 2 * 6))\n",
    "    axs[0, 0].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 0], linewidth=2, label=\"train loss\"\n",
    "    )\n",
    "    axs[0, 0].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 2], linewidth=2, label=\"test loss\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[0, 0].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 4],\n",
    "            linewidth=2,\n",
    "            label=\"ood test loss\",\n",
    "        )\n",
    "    axs[0, 0].set_yscale(\"log\")\n",
    "    axs[0, 0].set_title(\n",
    "        f\"Train/test loss, last/best test epoch {err_arr[-1,1]:.3f}, {np.min(err_arr[:,1]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[0, 0].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    axs[0, 1].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 1], linewidth=2, label=\"train err\"\n",
    "    )\n",
    "    axs[0, 1].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 3], linewidth=2, label=\"test err\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[0, 1].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 5],\n",
    "            linewidth=2,\n",
    "            label=\"ood test err\",\n",
    "        )\n",
    "    if opt_err is not None:\n",
    "        axs[0, 1].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            np.repeat(opt_err, num_epoch),\n",
    "            linestyle=\"dashed\",\n",
    "            label=\"optimal err\",\n",
    "        )\n",
    "    axs[0, 1].legend()\n",
    "    axs[0, 1].set_title(\n",
    "        f\"Train/test error, last/best test epoch {err_arr[-1,3]:.3f}, {np.min(err_arr[:,3]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[0, 1].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    axs[0, 2].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 6], linewidth=2, label=\"train err\"\n",
    "    )\n",
    "    axs[0, 2].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 7], linewidth=2, label=\"test err\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[0, 2].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 8],\n",
    "            linewidth=2,\n",
    "            label=\"ood test loss\",\n",
    "        )\n",
    "    axs[0, 2].set_yscale(\"log\")\n",
    "    axs[0, 2].set_title(\n",
    "        f\"Train/test loss only for IOI, last/best test epoch {err_arr[-1,7]:.3f}, {np.min(err_arr[:,7]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[0, 2].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    axs[1, 0].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 9], linewidth=2, label=\"train err\"\n",
    "    )\n",
    "    axs[1, 0].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 10], linewidth=2, label=\"test err\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[1, 0].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 11],\n",
    "            linewidth=2,\n",
    "            label=\"ood test loss\",\n",
    "        )\n",
    "    axs[1, 0].set_yscale(\"log\")\n",
    "    axs[1, 0].set_title(\n",
    "        f\"Train/test state prediction errors, last/best test epoch {err_arr[-1,10]:.3f}, {np.min(err_arr[:,10]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[1, 0].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    axs[1, 1].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 12], linewidth=2, label=\"train err\"\n",
    "    )\n",
    "    axs[1, 1].plot(\n",
    "        np.arange(num_epoch, dtype=int), err_arr[:, 13], linewidth=2, label=\"test err\"\n",
    "    )\n",
    "    if plot_ood:\n",
    "        axs[1, 1].plot(\n",
    "            np.arange(num_epoch, dtype=int),\n",
    "            err_arr[:, 14],\n",
    "            linewidth=2,\n",
    "            label=\"ood test loss\",\n",
    "        )\n",
    "    axs[1, 1].set_yscale(\"log\")\n",
    "    axs[1, 1].set_title(\n",
    "        f\"Train/test tran matrix prediction errors, last/best test epoch {err_arr[-1,13]:.3f}, {np.min(err_arr[:,13]):.3f}\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    axs[1, 1].set_xlabel(\"Epochs\", weight=\"bold\")\n",
    "    if fig_name is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def plot_attention(\n",
    "    model,\n",
    "    tokens,\n",
    "    fig_name,\n",
    "    norm=True,\n",
    "    pos=None,\n",
    "    savefig_dir=\"Figs\",\n",
    "    use_mask=True,\n",
    "    num_heads=1,\n",
    "    layer=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function makes two plots, namely attention plot and QK value heatmap\n",
    "    Args:\n",
    "        model: the simpleT model we use for the simulations\n",
    "        tokens: a sequence of tokens, where each token is any element of type torch.long in the vocabulary\n",
    "        fig_name: name of figure when saving plots\n",
    "        is_mask: if True, use a mask when calculating QK and attention for next-token prediction\n",
    "        num_heads: number of attention heads in the model\n",
    "    Returns:\n",
    "        QK_vals: the pre-softmax QK values, torch.Tensor 2-d array\n",
    "        attn: attentions, numpy 2-d array, normalized to sum 1\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    seq = (\n",
    "        model.pos_embed(model.embed(tokens.unsqueeze(0)))\n",
    "        if pos not in [\"rotary\", \"relative\"]\n",
    "        else model.embed(tokens.unsqueeze(0))\n",
    "    )\n",
    "    _, seq_len, d_model = seq.size()\n",
    "    d_k = d_model // num_heads\n",
    "    if d_model % num_heads != 0:\n",
    "        warnings.warn(\"d_model is not divisible by num_heads!\")\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).to(model.device)\n",
    "\n",
    "    h = seq\n",
    "    for layer0 in range(layer):\n",
    "        h = model.h[layer0](h, mask=mask)\n",
    "    h = model.h[layer].ln_1(h) if norm else h\n",
    "    queries = model.h[layer].mha.W_q(h)\n",
    "    keys = model.h[layer].mha.W_k(h)\n",
    "    values = model.h[layer].mha.W_v(h)\n",
    "    queries = queries.view(1, seq_len, num_heads, d_k).transpose(1, 2)\n",
    "    keys = keys.view(1, seq_len, num_heads, d_k).transpose(1, 2)\n",
    "    values = values.view(1, seq_len, num_heads, d_k).transpose(1, 2)\n",
    "\n",
    "    _, QKval = model.h[layer].mha.scaled_dot_product_attention(\n",
    "        queries, keys, values, mask=mask\n",
    "    )\n",
    "    attn, QK_vals = QKval[0].squeeze(dim=0).numpy(force=True), QKval[1].squeeze(\n",
    "        dim=0\n",
    "    ).numpy(force=True)\n",
    "\n",
    "    ## making plots now\n",
    "    fig, axs = plt.subplots(num_heads, 3, figsize=(3 * 9, num_heads * 9))\n",
    "    width = 1\n",
    "    example_sep = 2\n",
    "    word_height = 1\n",
    "    pad = 0.1\n",
    "    yoffset = 1\n",
    "    xoffset = 0\n",
    "\n",
    "    for head in range(num_heads):\n",
    "        plot_idx = (head, 0) if num_heads > 1 else 0\n",
    "        \"\"\"\n",
    "        for position, token in enumerate(tokens.numpy()):\n",
    "            axs[plot_idx].text(xoffset + 0,\n",
    "                     yoffset - position * word_height,\n",
    "                     token,\n",
    "                     ha=\"right\",\n",
    "                     va=\"center\")\n",
    "            axs[plot_idx].text(xoffset + width,\n",
    "                     yoffset - position * word_height,\n",
    "                     token,\n",
    "                     ha=\"left\",\n",
    "                     va=\"center\")\n",
    "        axs[plot_idx].text(xoffset + 0.5 * width,\n",
    "                 3,\n",
    "                 \"\",\n",
    "                 ha=\"center\",\n",
    "                 va=\"top\",\n",
    "                 weight=\"bold\")\n",
    "        for i in range(len(tokens)):\n",
    "            for j in range(len(tokens)):\n",
    "                axs[plot_idx].plot(\n",
    "                    [xoffset + pad, xoffset + width - pad],\n",
    "                    [yoffset - word_height * i, yoffset - word_height * j],\n",
    "                    color=\"blue\",\n",
    "                    linewidth=1,\n",
    "                    alpha=attn[head, i, j])\n",
    "                axs[plot_idx].set_title(f'Post-softmax attentions: head {head}',weight=\"bold\",fontsize=25)\n",
    "        \"\"\"\n",
    "\n",
    "        plot_idx = (head, 1) if num_heads > 1 else 1\n",
    "        pcm = axs[plot_idx].imshow(QK_vals[head, :, :])\n",
    "        axs[plot_idx].set_title(\n",
    "            f\"Pre-softmax QK values: head {head}\", weight=\"bold\", fontsize=25\n",
    "        )\n",
    "        fig.colorbar(pcm, ax=axs[plot_idx], shrink=0.8)\n",
    "\n",
    "        plot_idx = (head, 2) if num_heads > 1 else 2\n",
    "        pcm = axs[plot_idx].imshow(attn[head, :, :])\n",
    "        axs[plot_idx].set_title(\n",
    "            f\"Attention values: head {head}\", weight=\"bold\", fontsize=25\n",
    "        )\n",
    "        fig.colorbar(pcm, ax=axs[plot_idx], shrink=0.8)\n",
    "    plt.savefig(os.path.join(savefig_dir, fig_name), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return attn, QK_vals\n",
    "\n",
    "\n",
    "def plot_incoh_heatmat(save_dir, model, setting_params, remove_firstlast=True):\n",
    "    train_embed_str = \"trainEmbed_\" if setting_params[\"train_embed\"] else \"\"\n",
    "    add_embed_str = \"addEmbed_\" if setting_params[\"add_embed\"] else \"\"\n",
    "    MLP_str = \"MLP_\" if setting_params[\"use_MLP\"] else \"\"\n",
    "    sig = setting_params[\"sig\"]\n",
    "    plt_save_name = MLP_str + train_embed_str + add_embed_str + f\"sig_{sig}_incoh\"\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "    W_e = model.embed.embed.weight.detach().numpy()\n",
    "    Gram_e = W_e @ W_e.T\n",
    "    pcm = ax[0, 0].imshow(Gram_e)\n",
    "    fig.colorbar(pcm, ax=ax[0, 0], shrink=0.8)\n",
    "    ax[0, 0].set_title(\"Gram matrix of static embed matrix\", weight=\"bold\")\n",
    "\n",
    "    W_p = model.pos_embed.pe.weight.detach().numpy()\n",
    "    W_p = W_p[1:-1] if remove_firstlast else W_p\n",
    "    Gram_p = W_p @ W_p.T\n",
    "    pcm = ax[0, 1].imshow(Gram_p)\n",
    "    fig.colorbar(pcm, ax=ax[0, 1], shrink=0.8)\n",
    "    ax[0, 1].set_title(\"Gram matrix of positional embed matrix\", weight=\"bold\")\n",
    "\n",
    "    u, s, vt = np.linalg.svd(W_e)\n",
    "    ax[1, 0].plot(s)\n",
    "    ax[1, 0].set_xlabel(\"index\")\n",
    "    ax[1, 0].set_yscale(\"log\")\n",
    "    ax[1, 0].set_title(\"Spectrum of the static embed matrix\", weight=\"bold\")\n",
    "\n",
    "    u, s, vt = np.linalg.svd(W_p)\n",
    "    ax[1, 1].plot(s)\n",
    "    ax[1, 1].set_xlabel(\"index\")\n",
    "    ax[1, 1].set_yscale(\"log\")\n",
    "    ax[1, 1].set_title(\"Spectrum of the positional embed matrix\", weight=\"bold\")\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, plt_save_name), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def plot_err_over_pos(\n",
    "    model,\n",
    "    src_list,\n",
    "    vocab_size,\n",
    "    fig_name,\n",
    "    criterion=nn.CrossEntropyLoss(reduction=\"none\"),\n",
    "    lens=None,\n",
    "    src_labels=None,\n",
    "    starts=None,\n",
    "    return_predictions=False,\n",
    "    ignore_Aa=False,\n",
    "    save_dir=\"Figs\",\n",
    "):\n",
    "    \"\"\"\n",
    "    This function makes a plot to show the error of next-token prediction at each position\n",
    "    Args:\n",
    "        model: the simple TF model we use for the simulations\n",
    "        src_list: a list of datasets to test the model, 2D Tensor\n",
    "        vocab_size: size of vocabulary\n",
    "        fig_name: name of figure when saving plots\n",
    "        lens: a list/array of number of positions to ignore when calculting errors (useful when we want to exclude tokens not yet repeated)\n",
    "        return_predictions: if True, return predictions for each seq in src_list\n",
    "        ignore_Aa: (useful in Aa setting) if True, then case sensitivitity is ignored when calculating errors\n",
    "    Returns:\n",
    "        loss_list:  a list of arrays of length T-1 (max_seq_len-1), average loss at each position\n",
    "        err_list: a list of arrays of length T-1 (max_seq_len-1), average error at each position\n",
    "        pred_list: if return_predictions is True, a list of array of length T-1\n",
    "\n",
    "    \"\"\"\n",
    "    # if fig_name is not None:\n",
    "    #     if save_dir is None:\n",
    "    #         if not os.path.isdir(\"Figs\"):\n",
    "    #             os.mkdir(\"Figs\")\n",
    "    #         save_path = os.path.join(\"Figs\", fig_name)\n",
    "    #     else:\n",
    "    #         save_path = os.path.join(save_dir, fig_name)\n",
    "    # src_labels = [None] * len(src_list) if src_labels is None else src_labels\n",
    "    # lens = [None] * len(src_list) if lens is None else lens\n",
    "    # vocab_halfsize = vocab_size // 2\n",
    "    # eps = 1e-6\n",
    "    # model.eval()\n",
    "    # loss_list = []\n",
    "    # err_list = []\n",
    "    # pred_list = []\n",
    "\n",
    "    # for i, src in enumerate(src_list):\n",
    "    #     N, T = src.size()\n",
    "    #     M = torch.zeros(src.shape)\n",
    "    #     if lens[i] is not None:\n",
    "    #         M = torch.tensor(mask_get_along_axis(src.shape, lens[i]), device=src.device)\n",
    "    #     with torch.no_grad():\n",
    "    #         output = model(src)\n",
    "    #         loss = (\n",
    "    #             criterion(\n",
    "    #                 output[:, :-1].contiguous().view(-1, vocab_size),\n",
    "    #                 src[:, 1:].contiguous().view(-1),\n",
    "    #             )\n",
    "    #             .reshape(N, T - 1)\n",
    "    #             .mean(dim=0)\n",
    "    #         )\n",
    "    #         pred = output.argmax(dim=2)[:, :-1]\n",
    "    #         if ignore_Aa:\n",
    "    #             tmp = (\n",
    "    #                 (pred == src[:, 1:])\n",
    "    #                 | (pred == src[:, 1:] + vocab_halfsize)\n",
    "    #                 | (pred == src[:, 1:] - vocab_halfsize)\n",
    "    #             )\n",
    "    #         else:\n",
    "    #             tmp = pred == src[:, 1:]\n",
    "    #         err = 1 - torch.sum(tmp * M[:, :-1], dim=0) / (\n",
    "    #             torch.sum(M[:, :-1], dim=0) + eps\n",
    "    #         )\n",
    "    #     loss_list.append(loss.numpy(force=True))\n",
    "    #     err_list.append(err.numpy(force=True))\n",
    "    #     pred_list.append(pred.numpy(force=True))\n",
    "\n",
    "    # fig, axs = plt.subplots(2, 1, figsize=(10, 6 * 2))\n",
    "    # for i, src in enumerate(src_list):\n",
    "    #     axs[0].plot(\n",
    "    #         np.arange(T - 1, dtype=int), loss_list[i], \"-o\", label=src_labels[i]\n",
    "    #     )\n",
    "    #     axs[1].plot(np.arange(T - 1, dtype=int), err_list[i], \"-o\", label=src_labels[i])\n",
    "    # axs[0].set_xlabel(\"Position\", weight=\"bold\")\n",
    "    # axs[0].set_ylabel(\"Loss\", weight=\"bold\")\n",
    "    # axs[0].set_title(\n",
    "    #     \"Averaged next-token prediction loss at each position\", weight=\"bold\"\n",
    "    # )\n",
    "    # axs[1].set_xlabel(\"Position\", weight=\"bold\")\n",
    "    # axs[1].set_ylabel(\"Error\", weight=\"bold\")\n",
    "    # axs[1].set_title(\n",
    "    #     \"Averaged next-token prediction error at each position\", weight=\"bold\"\n",
    "    # )\n",
    "    # axs[0].legend()\n",
    "    # axs[1].legend()\n",
    "\n",
    "    # if fig_name is None:\n",
    "    #     plt.show()\n",
    "    # else:\n",
    "    #     plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    # out = (\n",
    "    #     (loss_list, err_list, pred_list)\n",
    "    #     if return_predictions\n",
    "    #     else (loss_list, err_list)\n",
    "    # )\n",
    "    # return out\n",
    "    if fig_name is not None:\n",
    "        if save_dir is None:\n",
    "            if not os.path.isdir(\"Figs\"):\n",
    "                os.mkdir(\"Figs\")\n",
    "            save_path = os.path.join(\"Figs\", fig_name)\n",
    "        else:\n",
    "            save_path = os.path.join(save_dir, fig_name)\n",
    "    src_labels = [None] * len(src_list) if src_labels is None else src_labels\n",
    "    lens = [None] * len(src_list) if lens is None else lens\n",
    "    vocab_halfsize = vocab_size // 2\n",
    "    eps = 1e-6\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    err_list = []\n",
    "    err2_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    for i, src in enumerate(src_list):\n",
    "        N, T = src.size()\n",
    "        M = torch.zeros(src.shape)\n",
    "        if lens[i] is not None:\n",
    "            M = torch.tensor(mask_get_given_starts(src.shape, lens[i], starts[i]))\n",
    "        with torch.no_grad():\n",
    "            output = model(src)\n",
    "            loss = (\n",
    "                criterion(\n",
    "                    output[:, :-1].contiguous().view(-1, vocab_size),\n",
    "                    src[:, 1:].contiguous().view(-1),\n",
    "                )\n",
    "                .reshape(N, T - 1)\n",
    "                .mean(dim=0)\n",
    "            )\n",
    "            pred = output.argmax(dim=2)[:, :-1]\n",
    "            if ignore_Aa:\n",
    "                tmp = (\n",
    "                    (pred == src[:, 1:])\n",
    "                    | (pred == src[:, 1:] + vocab_halfsize)\n",
    "                    | (pred == src[:, 1:] - vocab_halfsize)\n",
    "                )\n",
    "            else:\n",
    "                tmp = pred == src[:, 1:]\n",
    "        err = 1 - torch.sum(tmp.cpu() * M[:, :-1], dim=0) / (\n",
    "            torch.sum(M[:, :-1], dim=0) + eps\n",
    "        )  # averaged err at each posiiton\n",
    "        err2 = torch.zeros(vocab_size)\n",
    "        for j in range(vocab_size):\n",
    "            err2[j] = 1 - torch.sum((tmp * (src[:, :-1] == j)).cpu() * M[:, :-1]) / (\n",
    "                torch.sum((src[:, :-1] == j).cpu() * M[:, :-1]) + eps\n",
    "            )  # averaged err at each token\n",
    "        loss_list.append(loss.numpy(force=True))\n",
    "        err_list.append(err.numpy(force=True))\n",
    "        err2_list.append(err2.numpy(force=True))\n",
    "        pred_list.append(pred.numpy(force=True))\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 6 * 3))\n",
    "    for i, src in enumerate(src_list):\n",
    "        axs[0].plot(\n",
    "            np.arange(T - 1, dtype=int), loss_list[i], \"-o\", label=src_labels[i]\n",
    "        )\n",
    "        axs[1].plot(np.arange(T - 1, dtype=int), err_list[i], \"-o\", label=src_labels[i])\n",
    "        axs[2].plot(\n",
    "            np.arange(vocab_size, dtype=int), err2_list[i], \"-o\", label=src_labels[i]\n",
    "        )\n",
    "    axs[0].set_xlabel(\"Position\", weight=\"bold\")\n",
    "    axs[0].set_ylabel(\"Loss\", weight=\"bold\")\n",
    "    axs[0].set_title(\n",
    "        \"Averaged next-token prediction loss at each position\", weight=\"bold\"\n",
    "    )\n",
    "    axs[1].set_xlabel(\"Position\", weight=\"bold\")\n",
    "    axs[1].set_ylabel(\"Error\", weight=\"bold\")\n",
    "    axs[1].set_title(\n",
    "        \"Averaged next-token prediction error at each position\", weight=\"bold\"\n",
    "    )\n",
    "    axs[2].set_xlabel(\"Token\", weight=\"bold\")\n",
    "    axs[2].set_ylabel(\"Error\", weight=\"bold\")\n",
    "    axs[2].set_title(\n",
    "        \"Averaged next-token prediction error at each token\", weight=\"bold\"\n",
    "    )\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    axs[2].legend()\n",
    "\n",
    "    if fig_name is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    out = (\n",
    "        (loss_list, err_list, err2_list, pred_list)\n",
    "        if return_predictions\n",
    "        else (loss_list, err_list)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_qk_subspace_matching(model, fig_name, config):\n",
    "    num_svals_plot = 32\n",
    "    W_q = model.h[1].mha.W_q.weight.numpy(force=True)\n",
    "    W_k = model.h[1].mha.W_k.weight.numpy(force=True)\n",
    "    W_v = model.h[0].mha.W_v.weight.numpy(force=True)\n",
    "    W_o = model.h[0].mha.W_o.weight.numpy(force=True)\n",
    "    W_qk = W_q.T @ W_k / np.sqrt(config.d_model)\n",
    "    W_ov = W_o @ W_v\n",
    "    U_qk, s_qk, Vt_qk = np.linalg.svd(W_qk)\n",
    "    U_ov, s_ov, Vt_ov = np.linalg.svd(W_ov)\n",
    "\n",
    "    s_match = np.zeros((2, num_svals_plot))\n",
    "    for j in range(num_svals_plot):\n",
    "        _, s, _ = np.linalg.svd(Vt_qk[: (j + 1), :] @ U_ov[:, : (j + 1)])\n",
    "        _, s2, _ = np.linalg.svd(Vt_ov[: (j + 1), :] @ U_qk[:, : (j + 1)])\n",
    "        s_match[0, j] = s[0]\n",
    "        s_match[1, j] = s2[0]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6 * 2, 6 * 1))\n",
    "    axs[0].plot(s_qk[:num_svals_plot] / s_qk[0], \"-o\", label=\"qk\", linewidth=2)\n",
    "    axs[0].plot(s_ov[:num_svals_plot] / s_ov[0], \"-o\", label=\"ov\", linewidth=2)\n",
    "    axs[0].plot(s_match[0, :num_svals_plot], \"-o\", label=\"match\")\n",
    "    axs[0].legend()\n",
    "    axs[0].set_title(\"inner match\")\n",
    "    axs[1].plot(s_qk[:num_svals_plot] / s_qk[0], \"-o\", label=\"qk\", linewidth=2)\n",
    "    axs[1].plot(s_ov[:num_svals_plot] / s_ov[0], \"-o\", label=\"ov\", linewidth=2)\n",
    "    axs[1].plot(s_match[1, :num_svals_plot], \"-o\", label=\"match\")\n",
    "    axs[1].legend()\n",
    "    axs[1].set_title(\"outer match\")\n",
    "\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_wqkov(model, fig_name, config):\n",
    "    W_q = model.h[1].mha.W_q.weight.numpy(force=True)\n",
    "    W_k = model.h[1].mha.W_k.weight.numpy(force=True)\n",
    "    W_v = model.h[0].mha.W_v.weight.numpy(force=True)\n",
    "    W_o = model.h[0].mha.W_o.weight.numpy(force=True)\n",
    "    W_qk = W_q.T @ W_k / np.sqrt(config.d_model)\n",
    "    W_ov = W_o @ W_v\n",
    "    W_qkov = W_qk @ W_ov\n",
    "\n",
    "    ax = sns.heatmap(W_qkov, square=True)\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "#####################################################\n",
    "################# Calculating errors ################\n",
    "#####################################################\n",
    "\n",
    "\n",
    "def hmm_calc_err(\n",
    "    src_list, output_list, states_list, state_sizes, transition_mat, contains_ood=True\n",
    "):\n",
    "    \"\"\"\n",
    "    This function caluculates the errors after every epoch during training\n",
    "    Args:\n",
    "        src_list is a list containing train data, test data, ood data\n",
    "        output_list is a list containing next-token prediction probabilities based on train data, test data, ood data\n",
    "        states_list is a list containing hidden markov states for train data, test data, ood data\n",
    "        if contains_ood is False, the above lists do not contain ood data related data\n",
    "    Returns:\n",
    "        err_ratios: a list containing train/text/ood next-token prediction errors\n",
    "        err_states_ratios: a list containing errors for prediction hidden states, on train/text/ood respectively\n",
    "        err_probs_ratios: predicted transition matrix vs. true transition matrix, measured under L_1 loss, on train/text/ood respectively\n",
    "    \"\"\"\n",
    "    K = len(state_sizes)\n",
    "    assert np.all(\n",
    "        np.array([state_sizes[k] == state_sizes[0] for k in range(K)])\n",
    "    ), \"Currently only support identical state sizes\"\n",
    "    s = state_sizes[0]\n",
    "    err_ratios = torch.zeros(len(src_list))\n",
    "    err_states_ratios = torch.zeros(len(src_list))\n",
    "    err_probs_ratios = torch.zeros(len(src_list))\n",
    "    for k, (src, output, states) in enumerate(zip(src_list, output_list, states_list)):\n",
    "        sample_size, T, vocab_size = output.size(0), output.size(1), output.size(2)\n",
    "        pred = output.argmax(dim=2)\n",
    "        # cleaning; remove examples from counting errors if too few states are 0\n",
    "        nums_zero_state = torch.sum(states == 0, dim=1)\n",
    "        id_keep = (\n",
    "            nums_zero_state > 3\n",
    "        )  # remove some instances from dataset if too few satisfy states==0 such that ioi is impossible\n",
    "        sample_size_effective = torch.sum(id_keep)\n",
    "        src, states, output, pred = (\n",
    "            src[id_keep],\n",
    "            states[id_keep],\n",
    "            output[id_keep],\n",
    "            pred[id_keep],\n",
    "        )\n",
    "        # read states and probabilities from pred/output\n",
    "        pred_states = pred // s\n",
    "        pred_states = (\n",
    "            pred_states * (pred_states < K)\n",
    "        ).long()  # treating special symbols as having state 0\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        state_probs = probs[:, :, : (s * K)].view(sample_size, T, K, s).sum(axis=3)\n",
    "        state_probs[:, :, 0] += (\n",
    "            probs[:, :, (s * K) :].view(sample_size, T, -1).sum(axis=2)\n",
    "        )  # special symbols combined with state 0\n",
    "        pred_probs = torch.zeros(K, K)\n",
    "        for j1 in range(K):\n",
    "            for j2 in range(K):\n",
    "                pred_probs[j1, j2] = torch.sum(\n",
    "                    (states == j1) * state_probs[:, :, j2]\n",
    "                ) / torch.sum(states == j1)\n",
    "\n",
    "        loc1, loc2 = torch.nonzero(states == 0, as_tuple=True)\n",
    "        # loc1, loc2 = loc1[loc2!=0], loc2[loc2!=0] # NOTE: ignore this for now\n",
    "        total_err = torch.sum(src[loc1, loc2] != pred[loc1, loc2 - 1])\n",
    "        total_zero_state = len(loc1)\n",
    "        err_ratios[k] = (total_err - sample_size_effective) / (\n",
    "            total_zero_state - sample_size_effective\n",
    "        )\n",
    "        err_states_ratios[k] = torch.mean(\n",
    "            (pred_states[:, 2:-1] != states[:, 3:]).float()\n",
    "        )\n",
    "        err_probs_ratios[k] = torch.sum(torch.abs(pred_probs - transition_mat))\n",
    "\n",
    "    return err_ratios, err_states_ratios, err_probs_ratios\n",
    "\n",
    "\n",
    "######### making various plots ############\n",
    "\n",
    "\n",
    "def plots_maker(\n",
    "    model,\n",
    "    config,\n",
    "    src_list,\n",
    "    starts=None,\n",
    "    epoch=None,\n",
    "    lens=None,\n",
    "    save_dir=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Making various plots for a model during/after training\n",
    "    \"\"\"\n",
    "    assert len(src_list) == 3, \"Only supports includuing OOD data\"\n",
    "    src, src_test, src_test_ood = src_list\n",
    "    src_labels = [\"train\", \"test\", \"ood\"]\n",
    "    num_layers = config.num_layers\n",
    "    d_model = config.d_model\n",
    "\n",
    "    # plot errors at each position\n",
    "    _ = plot_err_over_pos(\n",
    "        model,\n",
    "        [src, src_test, src_test_ood],\n",
    "        config.vocab_size,\n",
    "        f\"err_over_pos_epoch_{epoch}\",\n",
    "        lens=lens,\n",
    "        starts=starts,\n",
    "        src_labels=[\"train\", \"test\", \"ood\"],\n",
    "        save_dir=save_dir,\n",
    "    )\n",
    "\n",
    "    # plot Gram matrix\n",
    "    if config.pos not in [\"rotary\", \"relative\"]:\n",
    "        wpe = F.normalize(model.pos_embed.pe.weight, dim=-1)\n",
    "        wte = F.normalize(model.embed.embed.weight, dim=-1)\n",
    "        basis = torch.concat([wpe, wte], dim=0).detach().numpy()\n",
    "        Gram = basis @ basis.T\n",
    "\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(12 * 1, 12 * 1))\n",
    "        sns.heatmap(Gram, ax=axs, vmin=-1, vmax=1, cmap=\"bwr\")\n",
    "        axs.set_title(\"Gram matrix: [pos, token]\", weight=\"bold\")\n",
    "        plt.savefig(os.path.join(save_dir, f\"Gram_matrix_epoch_{epoch}\"))\n",
    "        plt.close()\n",
    "\n",
    "    # plot attention\n",
    "    attn_dir = os.path.join(save_dir, \"attn\")\n",
    "    create_folder(attn_dir)\n",
    "    attn_list = {}\n",
    "    QK_list = {}\n",
    "    for layer in range(num_layers):\n",
    "        attn_list[layer] = []\n",
    "        QK_list[layer] = []\n",
    "        for k, src0 in enumerate(src_list):\n",
    "            attn, QK = plot_attention(\n",
    "                model,\n",
    "                src0[0, :],\n",
    "                pos=config.pos,\n",
    "                layer=layer,\n",
    "                num_heads=config.num_heads,\n",
    "                norm=config.norm,\n",
    "                fig_name=f\"_{src_labels[k]}_{layer}_epoch_{epoch}\",\n",
    "                savefig_dir=attn_dir,\n",
    "            )\n",
    "            attn_list[layer].append(attn)\n",
    "            QK_list[layer].append(QK)\n",
    "\n",
    "    if num_layers == 1:\n",
    "        layer1 = 0\n",
    "        W_q = model.h[layer1].mha.W_q.weight.numpy(force=True)\n",
    "        W_k = model.h[layer1].mha.W_k.weight.numpy(force=True)\n",
    "        W_v = model.h[layer1].mha.W_v.weight.numpy(force=True)\n",
    "        W_o = model.h[layer1].mha.W_o.weight.numpy(force=True)\n",
    "        W_qk = W_q.T @ W_k / np.sqrt(d_model)\n",
    "        W_ov = W_o @ W_v\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6 * 2, 6 * 1))\n",
    "        sns.heatmap(W_qk, ax=axs[0])\n",
    "        axs[0].set_title(\"W_qk\", weight=\"bold\")\n",
    "        sns.heatmap(W_ov, ax=axs[1])\n",
    "        axs[1].set_title(\"W_ov\", weight=\"bold\")\n",
    "        plt.savefig(os.path.join(save_dir, f\"QK_OV_visz_epoch_{epoch}\"))\n",
    "        plt.close()\n",
    "        return\n",
    "\n",
    "    # plot weight matrices\n",
    "    for layer1 in range(num_layers):\n",
    "        for layer2 in range(layer1 + 1, num_layers):\n",
    "            W_q = model.h[layer2].mha.W_q.weight.numpy(force=True)\n",
    "            W_k = model.h[layer2].mha.W_k.weight.numpy(force=True)\n",
    "            W_v = model.h[layer1].mha.W_v.weight.numpy(force=True)\n",
    "            W_o = model.h[layer1].mha.W_o.weight.numpy(force=True)\n",
    "            W_qk = W_q.T @ W_k / np.sqrt(d_model)\n",
    "            W_ov = W_o @ W_v\n",
    "            W_qkov = W_qk @ W_ov\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(6 * 3, 6 * 1))\n",
    "            sns.heatmap(W_qk, ax=axs[0], square=True)\n",
    "            axs[0].set_title(\"W_qk\", weight=\"bold\")\n",
    "            sns.heatmap(W_ov, ax=axs[1], square=True)\n",
    "            axs[1].set_title(\"W_ov\", weight=\"bold\")\n",
    "            sns.heatmap(W_qkov, ax=axs[2], square=True)\n",
    "            axs[2].set_title(\"W_qkov\", weight=\"bold\")\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    save_dir, f\"QK_OV_visz_layer_{layer1}_{layer2}_epoch_{epoch}\"\n",
    "                )\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "    # plot subspace matching\n",
    "    num_svals_plot = 32\n",
    "    U_qk, s_qk, Vt_qk = np.linalg.svd(W_qk)\n",
    "    U_ov, s_ov, Vt_ov = np.linalg.svd(W_ov)\n",
    "    s_match = np.zeros((2, num_svals_plot))\n",
    "    for j in range(num_svals_plot):\n",
    "        _, s, _ = np.linalg.svd(Vt_qk[: (j + 1), :] @ U_ov[:, : (j + 1)])\n",
    "        _, s2, _ = np.linalg.svd(Vt_ov[: (j + 1), :] @ U_qk[:, : (j + 1)])\n",
    "        s_match[0, j] = s[0]\n",
    "        s_match[1, j] = s2[0]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6 * 2, 6 * 1))\n",
    "    axs[0].plot(s_qk[:num_svals_plot] / s_qk[0], \"-o\", label=\"qk\", linewidth=2)\n",
    "    axs[0].plot(s_ov[:num_svals_plot] / s_ov[0], \"-o\", label=\"ov\", linewidth=2)\n",
    "    axs[0].plot(s_match[0, :num_svals_plot], \"-o\", label=\"match\")\n",
    "    axs[0].legend()\n",
    "    axs[0].set_title(\"inner match\")\n",
    "    axs[1].plot(s_qk[:num_svals_plot] / s_qk[0], \"-o\", label=\"qk\", linewidth=2)\n",
    "    axs[1].plot(s_ov[:num_svals_plot] / s_ov[0], \"-o\", label=\"ov\", linewidth=2)\n",
    "    axs[1].plot(s_match[1, :num_svals_plot], \"-o\", label=\"match\")\n",
    "    axs[1].legend()\n",
    "    axs[1].set_title(\"outer match\")\n",
    "    plt.savefig(os.path.join(save_dir, f\"subspace_matching_{epoch}\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Running config and setting\n",
    "setup configuration and running function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# Configuration class\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    This is the configuration class to store the configuration of a TFModel. It is used to\n",
    "    instantiate a model according to the specified arguments, defining the model architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "# Print PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "\n",
    "# Cell 2: Define Configuration Dictionary (replacing config_0.yaml)\n",
    "config_dict = {\n",
    "    # reproduce\n",
    "    \"seed\": 2026,\n",
    "    \n",
    "    # model\n",
    "    \"vocab_size\": 16,  # 32\n",
    "    \"d_model\": 32,  # 64\n",
    "    \"ff_dim\": 256,\n",
    "    \"num_heads\": 1,\n",
    "    \"num_layers\": 2,\n",
    "    \n",
    "    # TF model variants\n",
    "    \"linear_attn\": False,\n",
    "    \"residual\": True,\n",
    "    \"mlp\": False,\n",
    "    \"dropout\": 0.1,\n",
    "    \"norm\": True,\n",
    "    \"output_norm\": False,\n",
    "    \"trainable_norm\": False,\n",
    "    \"pos\": \"rotary\",\n",
    "    \"rotary_theta\": 10000,\n",
    "    \n",
    "    # data generation\n",
    "    \"max_seq_len\": 64,\n",
    "    \"sample_size\": 5000,\n",
    "    \"sample_size_test\": 5000,\n",
    "    \"regime\": \"varied repetition\",\n",
    "    \"distr\": \"two-level\",\n",
    "    \"rep_l\": 10,\n",
    "    \"rep_h\": 20,\n",
    "    \"ood_len_pattern\": 25,\n",
    "    \"pool_size\": None,\n",
    "    \"sig\": 2,\n",
    "    \n",
    "    # training\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"fancy_opt\": False,\n",
    "    \"use_wd\": True,\n",
    "    \"schedule\": \"constant\",\n",
    "    \"fresh_sample\": True,\n",
    "    \"label_smoothing\": False,\n",
    "    \"optimizer\": \"sam\",\n",
    "    \"lr\": 0.001,\n",
    "    \"wd\": 0.0005,\n",
    "    \"batch_size\": 50,\n",
    "    \"num_epoch\": 10000,\n",
    "    \n",
    "    # logging\n",
    "    \"wandb_log\": False,\n",
    "    \"plot_attn_every_epoch\": 100,\n",
    "    \"print_output\": False,\n",
    "    \"n_save\": 1,  # 500\n",
    "    \"up_to_first_save\": False,\n",
    "    \n",
    "    # eval\n",
    "    \"ignore_segment\": 1,\n",
    "    \"ignore_burning\": 4,\n",
    "    \n",
    "    # IO\n",
    "    \"out_dir\": \"out_sam_0.001\",\n",
    "    \n",
    "    # sharpness task\n",
    "    \"sharpness_step\": 1000,\n",
    "    \"sharpness_task\": None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scheduler(optimizer, config):\n",
    "    if config.schedule == \"constant\":\n",
    "        scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
    "    elif config.schedule == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, config.num_epoch\n",
    "        )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config_override=None):\n",
    "    \"\"\"\n",
    "    Main function to run the experiment.\n",
    "    Args:\n",
    "        config_override: Dictionary with parameters to override from default config\n",
    "    \"\"\"\n",
    "    # Create configuration\n",
    "    config_args = config_dict.copy()\n",
    "    if config_override:\n",
    "        for k, v in config_override.items():\n",
    "            if k not in config_args:\n",
    "                print(f\"Warning: {k} is not supported!\")\n",
    "            if v != config_args[k]:\n",
    "                print(f\"{k} is overloaded from {config_args[k]} to {v}\")\n",
    "                config_args[k] = v\n",
    "    \n",
    "    config = Config(**config_args)\n",
    "    \n",
    "    # Set random seed\n",
    "    fix_random_seed(config.seed, reproduce=True)\n",
    "    \n",
    "    # Create output directories\n",
    "    create_folder(config.out_dir)\n",
    "    create_folder(os.path.join(config.out_dir, \"figures\"))\n",
    "    \n",
    "    # Print and save configuration\n",
    "    print(\"Configuration:\")\n",
    "    for k, v in config.__dict__.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    \n",
    "    with open(os.path.join(config.out_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump(config.__dict__, f, indent=2)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TFModel(config).to(config.device)\n",
    "    \n",
    "    # Save initial model\n",
    "    out_path = os.path.join(config.out_dir, \"ckpt_0.pt\")\n",
    "    torch.save(model.state_dict(), out_path)\n",
    "    \n",
    "    # Setup optimizer\n",
    "    use_sam = False\n",
    "    if config.optimizer == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-9,\n",
    "            weight_decay=config.wd,\n",
    "        )\n",
    "    elif config.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config.lr,\n",
    "            momentum=0.9,\n",
    "            nesterov=True,\n",
    "            weight_decay=config.wd,\n",
    "        )\n",
    "    elif config.optimizer == \"sam\":\n",
    "        use_sam = True\n",
    "        base_optimizer = torch.optim.SGD\n",
    "        optimizer = SAM(\n",
    "            model.parameters(), \n",
    "            base_optimizer, \n",
    "            lr=config.lr,\n",
    "            momentum=0.9,\n",
    "            nesterov=True,\n",
    "            weight_decay=config.wd,\n",
    "        )\n",
    "    \n",
    "    # Setup scheduler\n",
    "    scheduler = make_scheduler(optimizer, config)\n",
    "    \n",
    "    # Train model\n",
    "    if config.fresh_sample:\n",
    "        model, err_arr, err_arr_json = train_infinite(\n",
    "            model=model,\n",
    "            config=config,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            use_sam=use_sam,\n",
    "        )\n",
    "    else:\n",
    "        model, err_arr, err_arr_json = train_finite(\n",
    "            model=model,\n",
    "            config=config,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "        )\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Save final model\n",
    "    out_path = os.path.join(config.out_dir, \"ckpt.pt\")\n",
    "    torch.save(model.state_dict(), out_path)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_err_curve(\n",
    "        err_arr,\n",
    "        fig_name=\"train_test_curves\",\n",
    "        save_dir=config.out_dir,\n",
    "        plot_ood=True,\n",
    "        plot_train=not config.fresh_sample,\n",
    "        log_training_time=config.fresh_sample,\n",
    "    )\n",
    "    \n",
    "    # Save error arrays\n",
    "    with open(os.path.join(config.out_dir, \"err_arr.json\"), \"w\") as f:\n",
    "        json.dump(err_arr_json, f, indent=2)\n",
    "    \n",
    "    print(f\"Experiment completed. Results saved in {config.out_dir}\")\n",
    "    \n",
    "    return model, err_arr, err_arr_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Actual run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  seed: 2026\n",
      "  vocab_size: 16\n",
      "  d_model: 32\n",
      "  ff_dim: 256\n",
      "  num_heads: 1\n",
      "  num_layers: 2\n",
      "  linear_attn: False\n",
      "  residual: True\n",
      "  mlp: False\n",
      "  dropout: 0.1\n",
      "  norm: True\n",
      "  output_norm: False\n",
      "  trainable_norm: False\n",
      "  pos: rotary\n",
      "  rotary_theta: 10000\n",
      "  max_seq_len: 64\n",
      "  sample_size: 5000\n",
      "  sample_size_test: 5000\n",
      "  regime: varied repetition\n",
      "  distr: two-level\n",
      "  rep_l: 10\n",
      "  rep_h: 20\n",
      "  ood_len_pattern: 25\n",
      "  pool_size: None\n",
      "  sig: 2\n",
      "  device: cuda\n",
      "  fancy_opt: False\n",
      "  use_wd: True\n",
      "  schedule: constant\n",
      "  fresh_sample: True\n",
      "  label_smoothing: False\n",
      "  optimizer: sam\n",
      "  lr: 0.001\n",
      "  wd: 0.0005\n",
      "  batch_size: 50\n",
      "  num_epoch: 10000\n",
      "  wandb_log: False\n",
      "  plot_attn_every_epoch: 100\n",
      "  print_output: False\n",
      "  n_save: 1\n",
      "  up_to_first_save: False\n",
      "  ignore_segment: 1\n",
      "  ignore_burning: 4\n",
      "  out_dir: out_sam_0.001\n",
      "  sharpness_step: 1000\n",
      "  sharpness_task: None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, err_arr, err_arr_json = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(config_override)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.fresh_sample:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     model, err_arr, err_arr_json = \u001b[43mtrain_infinite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m     model, err_arr, err_arr_json = train_finite(\n\u001b[32m     85\u001b[39m         model=model,\n\u001b[32m     86\u001b[39m         config=config,\n\u001b[32m     87\u001b[39m         optimizer=optimizer,\n\u001b[32m     88\u001b[39m         scheduler=scheduler,\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtrain_infinite\u001b[39m\u001b[34m(model, config, optimizer, scheduler, use_sam)\u001b[39m\n\u001b[32m     75\u001b[39m train_dataset = []\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     src, lens_train, starts_train, _ = \u001b[43mgen_simulated_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrep_l\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrep_l\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrep_h\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrep_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     M = get_mask(\n\u001b[32m     90\u001b[39m         src,\n\u001b[32m     91\u001b[39m         lens_train,\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m         ignore_burning=config.ignore_burning,\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     96\u001b[39m     train_dataset.append((src, lens_train, starts_train, _, M))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mgen_simulated_data\u001b[39m\u001b[34m(distr, vocab, max_seq_len, sample_size, regime, pool_size, patterns, rep_l, rep_h, device)\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src.to(device), lens, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m regime == \u001b[33m\"\u001b[39m\u001b[33mvaried repetition\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     src, lens, starts, patterns = \u001b[43mgen_repetition_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpattern_pool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_lens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrep_l\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrep_l\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrep_h\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrep_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src.to(device), lens, starts, patterns\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m regime == \u001b[33m\"\u001b[39m\u001b[33mmodular addition\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mgen_repetition_data\u001b[39m\u001b[34m(vocab, max_seq_len, sample_size, distr, pattern_pool_size, patterns, rep_l, rep_h, num_repeat, return_lens)\u001b[39m\n\u001b[32m    101\u001b[39m     pattern_len = \u001b[38;5;28mlen\u001b[39m(pattern_sample)\n\u001b[32m    103\u001b[39m r = max_seq_len - pattern_len * num_repeat\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m gaps = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_repeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplacement\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m gaps = torch.sort(gaps)[\u001b[32m0\u001b[39m]\n\u001b[32m    106\u001b[39m gaps = torch.cat(\n\u001b[32m    107\u001b[39m     (\n\u001b[32m    108\u001b[39m         gaps[:\u001b[32m1\u001b[39m],\n\u001b[32m    109\u001b[39m         torch.tensor([gaps[i] - gaps[i - \u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_repeat)]),\n\u001b[32m    110\u001b[39m     )\n\u001b[32m    111\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model, err_arr, err_arr_json = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "if isinstance(err_arr, dict):\n",
    "    for key, values in err_arr.items():\n",
    "        plt.plot(values, label=key)\n",
    "else:\n",
    "    plt.plot(err_arr)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reason",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
